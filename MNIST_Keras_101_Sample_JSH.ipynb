{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Keras-101-Sample-JSH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7xaCA9Fb15L2i0JH7DO8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbahk/graphcore-ipu-demo/blob/main/MNIST_Keras_101_Sample_JSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7GMXBHQvU7l"
      },
      "source": [
        "#Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Lmu3UgvJoH"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2o6ghk3vgj3"
      },
      "source": [
        "#Load MNIST DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-Zd6MFvnP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd652790-7189-43d6-a2ee-46ef80cf1dc6"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 60000\n",
            "# of y_train 60000\n",
            "# of x_test 10000\n",
            "# of y_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raERFh4uJque"
      },
      "source": [
        "#Transfer Learning 데모를 위한 Training Set 슬라이싱\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpIloZblJzFw",
        "outputId": "faaf422e-435f-41eb-ec29-af031d291412"
      },
      "source": [
        "tx_train = x_train[50000:]\n",
        "ty_train = y_train[50000:]\n",
        "\n",
        "x_train = x_train[0:50000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "\n",
        "print(\"# of tx_train\", len(tx_train))\n",
        "print(\"# of ty_train\", len(ty_train))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 50000\n",
            "# of y_train 50000\n",
            "# of tx_train 10000\n",
            "# of ty_train 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKMIfSetEwYQ"
      },
      "source": [
        "#ValidationSet을 위한 TestSet 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzz_2UlcE3Se",
        "outputId": "c972b0e7-b40d-4692-e6e0-615d0f84112c"
      },
      "source": [
        "x_val = x_test[5000:]\n",
        "y_val = y_test[5000:]\n",
        "\n",
        "x_test = x_test[0:5000]\n",
        "y_test = y_test[0:5000]\n",
        "\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))\n",
        "\n",
        "print(\"# of x_val\", len(x_val))\n",
        "print(\"# of y_val\", len(y_val))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_test 5000\n",
            "# of y_test 5000\n",
            "# of x_val 5000\n",
            "# of y_val 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tklx1amapQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45739f9a-4f2f-4cda-845f-21fcc5e790e8"
      },
      "source": [
        "for i in range(5):\n",
        "  print(y_train[i])\n",
        "#end of for"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0\n",
            "4\n",
            "1\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjNWl5tCW9lJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83c4f607-fcf6-46d5-9c83-46a88b1bd692"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_index = 1 # You may select anything up to 60,000\n",
        "\n",
        "print(x_train[image_index], \"\\n\\n\") # The label is 0\n",
        "print(x_test[image_index], \"\\n\\n\") # The label is 2\n",
        "\n",
        "print(y_train[image_index], \"\\n\\n\")\n",
        "print(y_test[image_index], \"\\n\\n\")\n",
        "\n",
        "print(\"x_train\", x_train.shape, \"x_test\", x_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "print(\"y_train\", y_train.shape, \"y_test\", y_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "\n",
        "\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
            "  159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
            "  252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
            "  233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
            "   84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
            "   96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
            "   47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
            "    0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
            "    0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
            "    0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
            "    0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
            "    7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
            "  131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
            "  252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
            "  162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
            "   56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0\n",
            "    5  20  20  37 150 150 150 147  10   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143\n",
            "  166 253 253 253 253 253 253 253 123   0]\n",
            " [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253\n",
            "  253 253 249 247 247 169 117 117  57   0]\n",
            " [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155\n",
            "  123 123  41   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "0 \n",
            "\n",
            "\n",
            "2 \n",
            "\n",
            "\n",
            "x_train (50000, 28, 28) x_test (5000, 28, 28) 리스트(배열,행렬)\n",
            "\n",
            "\n",
            "y_train (50000,) y_test (5000,) 리스트(배열,행렬)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc7473abf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUDbkQ6FwIu9"
      },
      "source": [
        "#one-hot enconding 수행<br>\n",
        "5 --> 0 0 0 0 0 1 0 0 0 0<br>\n",
        "1 --> 0 1 0 0 0 0 0 0 0 0<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEv9hkBBwEJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c659cd-6f11-4a6c-91f4-9eee95d014c6"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y=y_train, num_classes = 10)\n",
        "ty_train = keras.utils.to_categorical(y=ty_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y=y_test, num_classes=10)\n",
        "y_val = keras.utils.to_categorical(y=y_val, num_classes=10)\n",
        "\n",
        "#리스트 데이타들 출력해 보기\n",
        "for j in range(2):\n",
        "   print(\"\\n=====Y Train Value======\", y_train[j])\n",
        "#end of for\n",
        "\n",
        "for t in range(2):\n",
        "   print(\"\\n=====TY Train Value======\", ty_train[j])\n",
        "#end of for\n",
        "\n",
        "for k in range(2):\n",
        "   print(\"\\n=====Y Test Value======\", y_test[k])\n",
        "#end of for\n",
        "\n",
        "for v in range(2):\n",
        "   print(\"\\n=====Y Val Value======\", y_val[v])\n",
        "#end of for"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Y Train Value====== [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Train Value====== [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfwt_clw7Vt"
      },
      "source": [
        "#DataSet 형변환\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgegW8bww2bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1e88be-fa3e-4c35-e891-5b148813af6e"
      },
      "source": [
        "x_train = x_train.reshape(50000, 28*28)\n",
        "tx_train = tx_train.reshape(10000, 28*28)\n",
        "\n",
        "x_test = x_test.reshape(5000, 28*28)\n",
        "x_val = x_val.reshape(5000, 28*28)\n",
        "\n",
        "print(x_train.shape, tx_train.shape,  x_test.shape, x_val.shape)\n",
        "print(y_train.shape, ty_train.shape, y_test.shape, x_val.shape)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (10000, 784) (5000, 784) (5000, 784)\n",
            "(50000, 10) (10000, 10) (5000, 10) (5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP3f4krFIO-N"
      },
      "source": [
        "# https://www.youtube.com/watch?v=UOvPeC8WOt8"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3iM_wFCxmfm"
      },
      "source": [
        "#모델 구조 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYYrPFlxI1i"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\", input_shape=(28*28,)))\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VWPnAlNM17"
      },
      "source": [
        "모델구조 #보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuoRRK3tNWej"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.1), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmnw3IsqyYfc"
      },
      "source": [
        "#모델구성요소 컴파일 및 구조보기\n",
        "<br>파라메터 숫자: \n",
        "<br>dense_3: (28x28) x 32+32(bias) = 25120\n",
        "<br>dense_4: 32x32+32(bias) = 1056\n",
        "<br>dense_5: 32x10+10(bias) = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fpe0OuhyXW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582286b6-1821-4cbf-e152-1ac72b4fa8ff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_30 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_lwPmly8bG"
      },
      "source": [
        "#모델 훈련\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBBANgGMyy-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf68a4c7-b4ae-4fb8-b21d-bc6fd844e421"
      },
      "source": [
        "hist=model.fit(x=x_train, y=y_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 2.2383 - accuracy: 0.2427 - val_loss: 1.9422 - val_accuracy: 0.5898\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.8982 - accuracy: 0.5910 - val_loss: 1.6690 - val_accuracy: 0.7484\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.6435 - accuracy: 0.7125 - val_loss: 1.4087 - val_accuracy: 0.8200\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 1.4024 - accuracy: 0.7729 - val_loss: 1.1858 - val_accuracy: 0.8428\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.1965 - accuracy: 0.8013 - val_loss: 0.9941 - val_accuracy: 0.8704\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 1.0284 - accuracy: 0.8190 - val_loss: 0.8611 - val_accuracy: 0.8774\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.9014 - accuracy: 0.8331 - val_loss: 0.7518 - val_accuracy: 0.8852\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.8090 - accuracy: 0.8416 - val_loss: 0.6704 - val_accuracy: 0.8934\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.7291 - accuracy: 0.8538 - val_loss: 0.6033 - val_accuracy: 0.9024\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.6663 - accuracy: 0.8631 - val_loss: 0.5461 - val_accuracy: 0.9124\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.8676 - val_loss: 0.4982 - val_accuracy: 0.9102\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5782 - accuracy: 0.8704 - val_loss: 0.4670 - val_accuracy: 0.9128\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.5439 - accuracy: 0.8790 - val_loss: 0.4365 - val_accuracy: 0.9184\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.8847 - val_loss: 0.4219 - val_accuracy: 0.9126\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4874 - accuracy: 0.8860 - val_loss: 0.3858 - val_accuracy: 0.9216\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4628 - accuracy: 0.8923 - val_loss: 0.3652 - val_accuracy: 0.9248\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8986 - val_loss: 0.3508 - val_accuracy: 0.9304\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.9004 - val_loss: 0.3360 - val_accuracy: 0.9266\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8998 - val_loss: 0.3267 - val_accuracy: 0.9268\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4002 - accuracy: 0.8991 - val_loss: 0.3130 - val_accuracy: 0.9332\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.9066 - val_loss: 0.3058 - val_accuracy: 0.9310\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.9068 - val_loss: 0.2922 - val_accuracy: 0.9344\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3595 - accuracy: 0.9100 - val_loss: 0.2799 - val_accuracy: 0.9350\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3504 - accuracy: 0.9128 - val_loss: 0.2806 - val_accuracy: 0.9360\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.9096 - val_loss: 0.2699 - val_accuracy: 0.9398\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.9142 - val_loss: 0.2771 - val_accuracy: 0.9346\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3340 - accuracy: 0.9134 - val_loss: 0.2654 - val_accuracy: 0.9364\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.9127 - val_loss: 0.2461 - val_accuracy: 0.9388\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3158 - accuracy: 0.9164 - val_loss: 0.2506 - val_accuracy: 0.9404\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3158 - accuracy: 0.9158 - val_loss: 0.2435 - val_accuracy: 0.9412\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.9213 - val_loss: 0.2391 - val_accuracy: 0.9424\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.9205 - val_loss: 0.2378 - val_accuracy: 0.9412\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3039 - accuracy: 0.9186 - val_loss: 0.2262 - val_accuracy: 0.9440\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.9222 - val_loss: 0.2335 - val_accuracy: 0.9452\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2928 - accuracy: 0.9227 - val_loss: 0.2254 - val_accuracy: 0.9434\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2892 - accuracy: 0.9232 - val_loss: 0.2319 - val_accuracy: 0.9396\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.2740 - accuracy: 0.9269 - val_loss: 0.2128 - val_accuracy: 0.9462\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9264 - val_loss: 0.2065 - val_accuracy: 0.9492\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2753 - accuracy: 0.9250 - val_loss: 0.2148 - val_accuracy: 0.9448\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2692 - accuracy: 0.9266 - val_loss: 0.2155 - val_accuracy: 0.9432\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2738 - accuracy: 0.9239 - val_loss: 0.2138 - val_accuracy: 0.9404\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2748 - accuracy: 0.9240 - val_loss: 0.2032 - val_accuracy: 0.9462\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2594 - accuracy: 0.9290 - val_loss: 0.2116 - val_accuracy: 0.9456\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2634 - accuracy: 0.9273 - val_loss: 0.2051 - val_accuracy: 0.9472\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 0.2489 - accuracy: 0.9317 - val_loss: 0.1965 - val_accuracy: 0.9472\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2506 - accuracy: 0.9308 - val_loss: 0.1993 - val_accuracy: 0.9466\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2513 - accuracy: 0.9289 - val_loss: 0.1900 - val_accuracy: 0.9504\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.9312 - val_loss: 0.1910 - val_accuracy: 0.9480\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2465 - accuracy: 0.9312 - val_loss: 0.1952 - val_accuracy: 0.9482\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2441 - accuracy: 0.9327 - val_loss: 0.2035 - val_accuracy: 0.9446\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2447 - accuracy: 0.9318 - val_loss: 0.1950 - val_accuracy: 0.9498\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2478 - accuracy: 0.9298 - val_loss: 0.1907 - val_accuracy: 0.9512\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2427 - accuracy: 0.9315 - val_loss: 0.1968 - val_accuracy: 0.9466\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2416 - accuracy: 0.9323 - val_loss: 0.1783 - val_accuracy: 0.9512\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.9322 - val_loss: 0.1807 - val_accuracy: 0.9498\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2337 - accuracy: 0.9327 - val_loss: 0.1776 - val_accuracy: 0.9516\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2363 - accuracy: 0.9321 - val_loss: 0.1838 - val_accuracy: 0.9534\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2330 - accuracy: 0.9342 - val_loss: 0.1740 - val_accuracy: 0.9546\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2334 - accuracy: 0.9319 - val_loss: 0.1757 - val_accuracy: 0.9528\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.9306 - val_loss: 0.1724 - val_accuracy: 0.9502\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2305 - accuracy: 0.9334 - val_loss: 0.1766 - val_accuracy: 0.9518\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2241 - accuracy: 0.9353 - val_loss: 0.1829 - val_accuracy: 0.9496\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2241 - accuracy: 0.9359 - val_loss: 0.1806 - val_accuracy: 0.9510\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2254 - accuracy: 0.9351 - val_loss: 0.1808 - val_accuracy: 0.9472\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 0.9331 - val_loss: 0.1773 - val_accuracy: 0.9508\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2276 - accuracy: 0.9362 - val_loss: 0.1691 - val_accuracy: 0.9516\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2246 - accuracy: 0.9350 - val_loss: 0.1640 - val_accuracy: 0.9552\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2223 - accuracy: 0.9362 - val_loss: 0.1777 - val_accuracy: 0.9504\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2170 - accuracy: 0.9372 - val_loss: 0.1724 - val_accuracy: 0.9494\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9371 - val_loss: 0.1704 - val_accuracy: 0.9502\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.9356 - val_loss: 0.1669 - val_accuracy: 0.9522\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2077 - accuracy: 0.9422 - val_loss: 0.1604 - val_accuracy: 0.9534\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2084 - accuracy: 0.9400 - val_loss: 0.1653 - val_accuracy: 0.9528\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2023 - accuracy: 0.9417 - val_loss: 0.1598 - val_accuracy: 0.9594\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2152 - accuracy: 0.9363 - val_loss: 0.1729 - val_accuracy: 0.9510\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2158 - accuracy: 0.9367 - val_loss: 0.1591 - val_accuracy: 0.9574\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2068 - accuracy: 0.9416 - val_loss: 0.1601 - val_accuracy: 0.9540\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2064 - accuracy: 0.9409 - val_loss: 0.1581 - val_accuracy: 0.9578\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2046 - accuracy: 0.9416 - val_loss: 0.1756 - val_accuracy: 0.9534\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2014 - accuracy: 0.9412 - val_loss: 0.1583 - val_accuracy: 0.9582\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2033 - accuracy: 0.9407 - val_loss: 0.1548 - val_accuracy: 0.9560\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2020 - accuracy: 0.9419 - val_loss: 0.1726 - val_accuracy: 0.9518\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2063 - accuracy: 0.9401 - val_loss: 0.1525 - val_accuracy: 0.9596\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.9400 - val_loss: 0.1579 - val_accuracy: 0.9562\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2083 - accuracy: 0.9380 - val_loss: 0.1596 - val_accuracy: 0.9550\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.1957 - accuracy: 0.9432 - val_loss: 0.1593 - val_accuracy: 0.9550\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2054 - accuracy: 0.9398 - val_loss: 0.1510 - val_accuracy: 0.9572\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1905 - accuracy: 0.9443 - val_loss: 0.1560 - val_accuracy: 0.9548\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1921 - accuracy: 0.9453 - val_loss: 0.1528 - val_accuracy: 0.9598\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1957 - accuracy: 0.9422 - val_loss: 0.1611 - val_accuracy: 0.9560\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2024 - accuracy: 0.9398 - val_loss: 0.1509 - val_accuracy: 0.9598\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1948 - accuracy: 0.9440 - val_loss: 0.1445 - val_accuracy: 0.9572\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9442 - val_loss: 0.1548 - val_accuracy: 0.9570\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1969 - accuracy: 0.9420 - val_loss: 0.1601 - val_accuracy: 0.9528\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1959 - accuracy: 0.9423 - val_loss: 0.1506 - val_accuracy: 0.9566\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.1950 - accuracy: 0.9429 - val_loss: 0.1518 - val_accuracy: 0.9552\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 0.9443 - val_loss: 0.1490 - val_accuracy: 0.9564\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1922 - accuracy: 0.9441 - val_loss: 0.1633 - val_accuracy: 0.9526\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2042 - accuracy: 0.9400 - val_loss: 0.1525 - val_accuracy: 0.9570\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1876 - accuracy: 0.9457 - val_loss: 0.1551 - val_accuracy: 0.9564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWCAm0xgzmkE"
      },
      "source": [
        "#생성된 모델을 이용한 추론(평가, 예측)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnxTP2eMzRxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4f6fa5-2ce0-43d9-a058-bc21d85a4274"
      },
      "source": [
        "model.evaluate(x_test, y_test )"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.9162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2676244378089905, 0.9161999821662903]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uANcounvIun"
      },
      "source": [
        "#모델 수행 히스토리 그래프보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBbM_KBMDjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a95d1eab-c5f9-4b95-81b5-f61d61107868"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax =  plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='loss')\n",
        "#loss_ax.plot(hist.history['val_loss'], 'g', label='validation loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='accuracy')\n",
        "#acc_ax.plot(hist.history['val_accuracy'], 'r', label='validation accuracy')\n",
        "\n",
        "plt.legend(['loss', 'accuracy'])\n",
        "#plt.legend(['train loss', 'train accuracy', 'validation loss', 'validation accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmWHScXJQgSE"
      },
      "source": [
        "#모델 바이러리(Weight) 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t44H7KrIQoQe"
      },
      "source": [
        "model.save(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "model.save_weights(\"MNIST-Keras-101-Pre_trained_weights\")"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOQQwtFmRMoJ"
      },
      "source": [
        "#저장된 모델 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cWH_rcCRP7A",
        "outputId": "2510d441-abf9-4efa-fba8-66ff4e38a56f"
      },
      "source": [
        "from keras.models import load_model\n",
        "ts_model = load_model(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "ts_model.summary()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_30 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gum-itSIRQX9"
      },
      "source": [
        "#로드된 모델에 새로운 데이타 Re-Training(Transfer Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za-OTrT4RaSp",
        "outputId": "0beb1bf4-e074-44a0-e3c2-be11be9ad04c"
      },
      "source": [
        "hist=ts_model.fit(x=tx_train, y=ty_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.2060 - accuracy: 0.9391 - val_loss: 0.1634 - val_accuracy: 0.9548\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2012 - accuracy: 0.9391 - val_loss: 0.1556 - val_accuracy: 0.9552\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1957 - accuracy: 0.9423 - val_loss: 0.1493 - val_accuracy: 0.9566\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1956 - accuracy: 0.9439 - val_loss: 0.1602 - val_accuracy: 0.9534\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1917 - accuracy: 0.9447 - val_loss: 0.1484 - val_accuracy: 0.9586\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1831 - accuracy: 0.9463 - val_loss: 0.1551 - val_accuracy: 0.9558\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1789 - accuracy: 0.9475 - val_loss: 0.1483 - val_accuracy: 0.9592\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1816 - accuracy: 0.9469 - val_loss: 0.1485 - val_accuracy: 0.9570\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9509 - val_loss: 0.1484 - val_accuracy: 0.9576\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1741 - accuracy: 0.9518 - val_loss: 0.1514 - val_accuracy: 0.9580\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1750 - accuracy: 0.9526 - val_loss: 0.1514 - val_accuracy: 0.9584\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1924 - accuracy: 0.9452 - val_loss: 0.1619 - val_accuracy: 0.9552\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1807 - accuracy: 0.9495 - val_loss: 0.1472 - val_accuracy: 0.9574\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1709 - accuracy: 0.9516 - val_loss: 0.1573 - val_accuracy: 0.9590\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1745 - accuracy: 0.9491 - val_loss: 0.1582 - val_accuracy: 0.9538\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1718 - accuracy: 0.9508 - val_loss: 0.1505 - val_accuracy: 0.9588\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1640 - accuracy: 0.9536 - val_loss: 0.1424 - val_accuracy: 0.9598\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1587 - accuracy: 0.9550 - val_loss: 0.1417 - val_accuracy: 0.9614\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9526 - val_loss: 0.1424 - val_accuracy: 0.9604\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9542 - val_loss: 0.1444 - val_accuracy: 0.9602\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1590 - accuracy: 0.9546 - val_loss: 0.1389 - val_accuracy: 0.9598\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1644 - accuracy: 0.9520 - val_loss: 0.1447 - val_accuracy: 0.9596\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1554 - accuracy: 0.9561 - val_loss: 0.1408 - val_accuracy: 0.9608\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1528 - accuracy: 0.9548 - val_loss: 0.1376 - val_accuracy: 0.9654\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1503 - accuracy: 0.9555 - val_loss: 0.1420 - val_accuracy: 0.9622\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1530 - accuracy: 0.9568 - val_loss: 0.1377 - val_accuracy: 0.9626\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9590 - val_loss: 0.1336 - val_accuracy: 0.9638\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1486 - accuracy: 0.9595 - val_loss: 0.1366 - val_accuracy: 0.9642\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1470 - accuracy: 0.9568 - val_loss: 0.1369 - val_accuracy: 0.9632\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1421 - accuracy: 0.9599 - val_loss: 0.1373 - val_accuracy: 0.9638\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1471 - accuracy: 0.9602 - val_loss: 0.1411 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1414 - accuracy: 0.9605 - val_loss: 0.1404 - val_accuracy: 0.9626\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1442 - accuracy: 0.9583 - val_loss: 0.1485 - val_accuracy: 0.9590\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1499 - accuracy: 0.9596 - val_loss: 0.1522 - val_accuracy: 0.9526\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1486 - accuracy: 0.9578 - val_loss: 0.1525 - val_accuracy: 0.9540\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1519 - accuracy: 0.9576 - val_loss: 0.1589 - val_accuracy: 0.9520\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1589 - accuracy: 0.9545 - val_loss: 0.1584 - val_accuracy: 0.9546\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1524 - accuracy: 0.9576 - val_loss: 0.1517 - val_accuracy: 0.9568\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1519 - accuracy: 0.9561 - val_loss: 0.1492 - val_accuracy: 0.9562\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1458 - accuracy: 0.9588 - val_loss: 0.1432 - val_accuracy: 0.9602\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1407 - accuracy: 0.9607 - val_loss: 0.1402 - val_accuracy: 0.9610\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.1369 - accuracy: 0.9611 - val_loss: 0.1444 - val_accuracy: 0.9580\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1404 - accuracy: 0.9608 - val_loss: 0.1468 - val_accuracy: 0.9574\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1381 - accuracy: 0.9607 - val_loss: 0.1468 - val_accuracy: 0.9594\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1310 - accuracy: 0.9634 - val_loss: 0.1376 - val_accuracy: 0.9624\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1313 - accuracy: 0.9640 - val_loss: 0.1425 - val_accuracy: 0.9604\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1327 - accuracy: 0.9628 - val_loss: 0.1426 - val_accuracy: 0.9580\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1354 - accuracy: 0.9628 - val_loss: 0.1430 - val_accuracy: 0.9602\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1337 - accuracy: 0.9627 - val_loss: 0.1450 - val_accuracy: 0.9592\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1330 - accuracy: 0.9631 - val_loss: 0.1420 - val_accuracy: 0.9602\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1249 - accuracy: 0.9669 - val_loss: 0.1401 - val_accuracy: 0.9604\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1274 - accuracy: 0.9644 - val_loss: 0.1433 - val_accuracy: 0.9612\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1277 - accuracy: 0.9648 - val_loss: 0.1421 - val_accuracy: 0.9598\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1279 - accuracy: 0.9641 - val_loss: 0.1402 - val_accuracy: 0.9600\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1265 - accuracy: 0.9668 - val_loss: 0.1403 - val_accuracy: 0.9592\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1249 - accuracy: 0.9665 - val_loss: 0.1470 - val_accuracy: 0.9572\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1251 - accuracy: 0.9666 - val_loss: 0.1454 - val_accuracy: 0.9588\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1233 - accuracy: 0.9673 - val_loss: 0.1404 - val_accuracy: 0.9594\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9663 - val_loss: 0.1437 - val_accuracy: 0.9572\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1203 - accuracy: 0.9674 - val_loss: 0.1346 - val_accuracy: 0.9632\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1204 - accuracy: 0.9680 - val_loss: 0.1408 - val_accuracy: 0.9582\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1262 - accuracy: 0.9661 - val_loss: 0.1397 - val_accuracy: 0.9600\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9667 - val_loss: 0.1427 - val_accuracy: 0.9586\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1248 - accuracy: 0.9656 - val_loss: 0.1383 - val_accuracy: 0.9608\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1223 - accuracy: 0.9661 - val_loss: 0.1325 - val_accuracy: 0.9632\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1211 - accuracy: 0.9659 - val_loss: 0.1379 - val_accuracy: 0.9592\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1171 - accuracy: 0.9686 - val_loss: 0.1395 - val_accuracy: 0.9590\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1110 - accuracy: 0.9716 - val_loss: 0.1341 - val_accuracy: 0.9602\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1109 - accuracy: 0.9710 - val_loss: 0.1387 - val_accuracy: 0.9590\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1121 - accuracy: 0.9711 - val_loss: 0.1378 - val_accuracy: 0.9590\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1131 - accuracy: 0.9693 - val_loss: 0.1466 - val_accuracy: 0.9564\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1155 - accuracy: 0.9704 - val_loss: 0.1377 - val_accuracy: 0.9610\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1118 - accuracy: 0.9716 - val_loss: 0.1383 - val_accuracy: 0.9618\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.9708 - val_loss: 0.1392 - val_accuracy: 0.9598\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1067 - accuracy: 0.9734 - val_loss: 0.1381 - val_accuracy: 0.9592\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1042 - accuracy: 0.9751 - val_loss: 0.1358 - val_accuracy: 0.9600\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 0.9736 - val_loss: 0.1396 - val_accuracy: 0.9588\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1069 - accuracy: 0.9743 - val_loss: 0.1388 - val_accuracy: 0.9592\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1052 - accuracy: 0.9743 - val_loss: 0.1385 - val_accuracy: 0.9594\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1081 - accuracy: 0.9727 - val_loss: 0.1379 - val_accuracy: 0.9602\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1078 - accuracy: 0.9721 - val_loss: 0.1396 - val_accuracy: 0.9576\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1056 - accuracy: 0.9736 - val_loss: 0.1352 - val_accuracy: 0.9606\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1029 - accuracy: 0.9741 - val_loss: 0.1375 - val_accuracy: 0.9582\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1034 - accuracy: 0.9742 - val_loss: 0.1344 - val_accuracy: 0.9628\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9742 - val_loss: 0.1304 - val_accuracy: 0.9640\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1034 - accuracy: 0.9732 - val_loss: 0.1424 - val_accuracy: 0.9600\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1058 - accuracy: 0.9734 - val_loss: 0.1344 - val_accuracy: 0.9608\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1029 - accuracy: 0.9730 - val_loss: 0.1399 - val_accuracy: 0.9608\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1056 - accuracy: 0.9718 - val_loss: 0.1368 - val_accuracy: 0.9606\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1031 - accuracy: 0.9730 - val_loss: 0.1360 - val_accuracy: 0.9638\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 0.1343 - val_accuracy: 0.9640\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1006 - accuracy: 0.9744 - val_loss: 0.1366 - val_accuracy: 0.9612\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1012 - accuracy: 0.9744 - val_loss: 0.1342 - val_accuracy: 0.9624\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0999 - accuracy: 0.9754 - val_loss: 0.1354 - val_accuracy: 0.9596\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1020 - accuracy: 0.9741 - val_loss: 0.1359 - val_accuracy: 0.9618\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1017 - accuracy: 0.9744 - val_loss: 0.1326 - val_accuracy: 0.9624\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0999 - accuracy: 0.9757 - val_loss: 0.1340 - val_accuracy: 0.9620\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1019 - accuracy: 0.9736 - val_loss: 0.1344 - val_accuracy: 0.9630\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0986 - accuracy: 0.9756 - val_loss: 0.1352 - val_accuracy: 0.9622\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0969 - accuracy: 0.9757 - val_loss: 0.1368 - val_accuracy: 0.9602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kctpWPoVVdfT",
        "outputId": "9975e48d-6b53-4ce0-f745-928b92af3dfd"
      },
      "source": [
        "ts_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.9210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2494920939207077, 0.9210000038146973]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKfJLRG0XFJm"
      },
      "source": [
        "model.save(\"MNIST-Keras-101-Transfer_learned.h5\")\n",
        "model.save_weights(\"MNIST-Keras-101-Transfer_learned_weights\")"
      ],
      "execution_count": 170,
      "outputs": []
    }
  ]
}