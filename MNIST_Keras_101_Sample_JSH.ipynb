{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Keras-101-Sample-JSH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNGxNK87l+/f/AXVxJV9gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbahk/graphcore-ipu-demo/blob/main/MNIST_Keras_101_Sample_JSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7GMXBHQvU7l"
      },
      "source": [
        "#Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Lmu3UgvJoH"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2o6ghk3vgj3"
      },
      "source": [
        "#Load MNIST DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-Zd6MFvnP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad6e1d7-26c1-42a5-ce3f-c2bbc3cb33e5"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 60000\n",
            "# of y_train 60000\n",
            "# of x_test 10000\n",
            "# of y_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raERFh4uJque"
      },
      "source": [
        "#Transfer Learning 데모를 위한 Training Set 슬라이싱\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpIloZblJzFw",
        "outputId": "3016dc1f-fc63-40ab-fc45-06bf64e6428b"
      },
      "source": [
        "tx_train = x_train[50000:]\n",
        "ty_train = y_train[50000:]\n",
        "\n",
        "x_train = x_train[0:50000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "\n",
        "print(\"# of tx_train\", len(tx_train))\n",
        "print(\"# of ty_train\", len(ty_train))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 50000\n",
            "# of y_train 50000\n",
            "# of tx_train 10000\n",
            "# of ty_train 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKMIfSetEwYQ"
      },
      "source": [
        "#ValidationSet을 위한 리스트 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzz_2UlcE3Se",
        "outputId": "a0791d91-dcd4-4811-a6fb-4e7d1ce8e9e8"
      },
      "source": [
        "x_val = x_test[5000:]\n",
        "y_val = y_test[5000:]\n",
        "\n",
        "x_test = x_test[0:5000]\n",
        "y_test = y_test[0:5000]\n",
        "\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))\n",
        "\n",
        "print(\"# of x_val\", len(x_val))\n",
        "print(\"# of y_val\", len(y_val))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_test 5000\n",
            "# of y_test 5000\n",
            "# of x_val 5000\n",
            "# of y_val 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tklx1amapQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554546c9-26ec-4e34-b509-3b55d0033549"
      },
      "source": [
        "for i in range(5):\n",
        "  print(y_train[i])\n",
        "#end of for"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0\n",
            "4\n",
            "1\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjNWl5tCW9lJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f33b4c7-5650-4145-c452-f62eeeed3f0c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_index = 1 # You may select anything up to 60,000\n",
        "\n",
        "print(x_train[image_index], \"\\n\\n\") # The label is 0\n",
        "print(x_test[image_index], \"\\n\\n\") # The label is 2\n",
        "\n",
        "print(y_train[image_index], \"\\n\\n\")\n",
        "print(y_test[image_index], \"\\n\\n\")\n",
        "\n",
        "print(\"x_train\", x_train.shape, \"x_test\", x_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "print(\"y_train\", y_train.shape, \"y_test\", y_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "\n",
        "\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
            "  159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
            "  252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
            "  233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
            "   84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
            "   96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
            "   47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
            "    0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
            "    0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
            "    0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
            "    0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
            "    7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
            "  131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
            "  252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
            "  162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
            "   56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0\n",
            "    5  20  20  37 150 150 150 147  10   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143\n",
            "  166 253 253 253 253 253 253 253 123   0]\n",
            " [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253\n",
            "  253 253 249 247 247 169 117 117  57   0]\n",
            " [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155\n",
            "  123 123  41   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "0 \n",
            "\n",
            "\n",
            "2 \n",
            "\n",
            "\n",
            "x_train (50000, 28, 28) x_test (5000, 28, 28) 리스트(배열,행렬)\n",
            "\n",
            "\n",
            "y_train (50000,) y_test (5000,) 리스트(배열,행렬)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc7443e4940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOdUlEQVR4nO3dfayU5ZnH8d8lLb4AEpAjQXvicRETtYnQTMgmJQ2bug3oH0h8CUQJa4g0BJSa+haMqTGayLotSlyJsBBw7dI0FCN/mLVKGrF/2DgClRezq4sH4QQ5hwip1Wh5ufaP89gc8Tz3HGaemWfg+n6Sycw819znuTL645l57pm5zd0F4Nx3XtkNAGgNwg4EQdiBIAg7EARhB4L4Tit3Nm7cOO/q6mrlLoFQuru7deTIERus1lDYzWyGpGclDZP0H+7+VOrxXV1dqlarjewSQEKlUsmt1f0y3syGSfp3STMlXStprpldW+/fA9BcjbxnnyrpQ3ff5+5/k/QbSbOKaQtA0RoJ++WSDgy4fzDb9g1mttDMqmZW7evra2B3ABrR9LPx7r7a3SvuXuno6Gj27gDkaCTsPZI6B9z/XrYNQBtqJOzvSJpkZlea2XBJcyRtKaYtAEWre+rN3U+Y2RJJr6l/6m2du+8prDMAhWpont3dX5X0akG9AGgiPi4LBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBAtXbIZ554DBw4k688++2xubcWKFcmx9913X7K+dOnSZL2zszNZj4YjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTw7knp6epL1KVOmJOvHjh3LrZlZcuwzzzyTrG/YsCFZ7+vrS9ajaSjsZtYt6TNJJyWdcPdKEU0BKF4RR/Z/cvcjBfwdAE3Ee3YgiEbD7pJ+b2bvmtnCwR5gZgvNrGpmVd5DAeVpNOzT3P0HkmZKWmxmPzr9Ae6+2t0r7l7p6OhocHcA6tVQ2N29J7vulfSypKlFNAWgeHWH3cxGmNmor29L+omk3UU1BqBYjZyNHy/p5Wyu9DuS/svd/7uQrtAy+/fvT9anT5+erB89ejRZT82ljx49Ojn2/PPPT9Z7e3uT9X379uXWrrjiiuTYYcOGJetno7rD7u77JF1fYC8AmoipNyAIwg4EQdiBIAg7EARhB4LgK67ngOPHj+fWak2tzZgxI1mv9VPRjZg8eXKy/uSTTybr06ZNS9YnTZqUW1u9enVy7IIFC5L1sxFHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2c8ADDzyQW3vuueda2MmZefPNN5P1zz//PFmfPXt2sr558+bc2o4dO5Jjz0Uc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZzwK1vlP+0ksv5dbcvaF915rLvuWWW5L1O++8M7fW2dmZHHvNNdck6w899FCyvmnTptxao8/L2YgjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EYa2cb6xUKl6tVlu2v7NFT09Psn799enFco8dO1b3vu+4445kfc2aNcn63r17k/Xt27fn1ubMmZMce9FFFyXrtaSWXR4xYkRy7J49e5L1Wp8RKEulUlG1Wh10neyaR3YzW2dmvWa2e8C2sWb2upl9kF2PKbJhAMUbysv49ZJOXzbkYUlb3X2SpK3ZfQBtrGbY3X2bpE9P2zxL0obs9gZJNxfcF4CC1XuCbry7H8pufyJpfN4DzWyhmVXNrNrX11fn7gA0quGz8d5/hi/3LJ+7r3b3irtXOjo6Gt0dgDrVG/bDZjZBkrLr3uJaAtAM9YZ9i6T52e35kl4pph0AzVLz++xmtlHSdEnjzOygpF9IekrSb81sgaT9km5vZpNnuyNHjiTry5cvT9aPHj2arI8fn3vKRFdeeWVy7KJFi5L14cOHJ+u11livVS/LF198kaw//fTTyfrKlSuLbKclaobd3efmlH5ccC8AmoiPywJBEHYgCMIOBEHYgSAIOxAEPyVdgBMnTiTr999/f7Ke+iloSRo9enSy/tprr+XWrrrqquTY48ePJ+tRffTRR2W3UDiO7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBPPsBfj444+T9Vrz6LW8/fbbyfrVV19d99++8MIL6x6LswtHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2AixevDhZr7Us9uzZs5P1RubRIzt16lRu7bzz0se5Vi5l3ioc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZh2jHjh25tW3btiXHmlmyftttt9XVE9JSc+m1/ptUKpWi2yldzSO7ma0zs14z2z1g22Nm1mNmO7PLjc1tE0CjhvIyfr2kGYNsX+Huk7PLq8W2BaBoNcPu7tskfdqCXgA0USMn6JaY2XvZy/wxeQ8ys4VmVjWzal9fXwO7A9CIesO+StJESZMlHZL0y7wHuvtqd6+4e6Wjo6PO3QFoVF1hd/fD7n7S3U9JWiNparFtAShaXWE3swkD7s6WtDvvsQDaQ815djPbKGm6pHFmdlDSLyRNN7PJklxSt6SfNrHHtvDll1/m1r766qvk2MsuuyxZv+mmm+rq6VxXa937lStX1v23b7311mR92bJldf/tdlUz7O4+d5DNa5vQC4Am4uOyQBCEHQiCsANBEHYgCMIOBMFXXFvgggsuSNZHjhzZok7aS62ptVWrViXrDz74YLLe1dWVW3vkkUeSY4cPH56sn404sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMyzt8C8efPKbqE0PT09ubXly5cnxz7//PPJ+l133ZWsr1mzJlmPhiM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPPsQuXtdNUlav359sv7oo4/W01Jb2LhxY7J+zz335NaOHj2aHHvvvfcm6ytWrEjW8U0c2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZh8jM6qpJ0sGDB5P1xx9/PFlfsGBBsj5q1Kjc2p49e5JjX3jhhWT9rbfeSta7u7uT9YkTJ+bW5syZkxxba54dZ6bmkd3MOs3sD2a218z2mNnSbPtYM3vdzD7Irsc0v10A9RrKy/gTkn7u7tdK+kdJi83sWkkPS9rq7pMkbc3uA2hTNcPu7ofcfXt2+zNJ70u6XNIsSRuyh22QdHOzmgTQuDM6QWdmXZKmSPqTpPHufigrfSJpfM6YhWZWNbNqX19fA60CaMSQw25mIyX9TtLP3P0vA2ve/02QQb8N4u6r3b3i7pWOjo6GmgVQvyGF3cy+q/6g/9rdN2ebD5vZhKw+QVJvc1oEUISaU2/WP6+0VtL77v6rAaUtkuZLeiq7fqUpHZ4DTp48mazXmnpbu3Ztsj527Njc2q5du5JjGzVz5sxkfcaMGbm1JUuWFN0OEoYyz/5DSfMk7TKzndm2ZeoP+W/NbIGk/ZJub06LAIpQM+zu/kdJeZ8a+XGx7QBoFj4uCwRB2IEgCDsQBGEHgiDsQBB8xXWIrrvuutzaDTfckBz7xhtvNLTvWl+RTS2LXMull16arC9atChZP5t/BjsajuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATz7EN08cUX59Y2bdqUHPviiy8m6838yeQnnngiWb/77ruT9UsuuaTIdlAijuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EIT1L+bSGpVKxavVasv2B0RTqVRUrVYH/TVojuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EETNsJtZp5n9wcz2mtkeM1uabX/MzHrMbGd2ubH57QKo11B+vOKEpJ+7+3YzGyXpXTN7PautcPd/a157AIoylPXZD0k6lN3+zMzel3R5sxsDUKwzes9uZl2Spkj6U7ZpiZm9Z2brzGxMzpiFZlY1s2pfX19DzQKo35DDbmYjJf1O0s/c/S+SVkmaKGmy+o/8vxxsnLuvdveKu1c6OjoKaBlAPYYUdjP7rvqD/mt33yxJ7n7Y3U+6+ylJayRNbV6bABo1lLPxJmmtpPfd/VcDtk8Y8LDZknYX3x6AogzlbPwPJc2TtMvMdmbblkmaa2aTJbmkbkk/bUqHAAoxlLPxf5Q02PdjXy2+HQDNwifogCAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQbR0yWYz65O0f8CmcZKOtKyBM9OuvbVrXxK91avI3q5w90F//62lYf/Wzs2q7l4prYGEdu2tXfuS6K1ereqNl/FAEIQdCKLssK8uef8p7dpbu/Yl0Vu9WtJbqe/ZAbRO2Ud2AC1C2IEgSgm7mc0ws/8xsw/N7OEyeshjZt1mtitbhrpaci/rzKzXzHYP2DbWzF43sw+y60HX2Cupt7ZYxjuxzHipz13Zy5+3/D27mQ2T9L+S/lnSQUnvSJrr7ntb2kgOM+uWVHH30j+AYWY/kvRXSS+6+/ezbf8q6VN3fyr7h3KMuz/UJr09JumvZS/jna1WNGHgMuOSbpb0LyrxuUv0dbta8LyVcWSfKulDd9/n7n+T9BtJs0roo+25+zZJn562eZakDdntDer/n6XlcnprC+5+yN23Z7c/k/T1MuOlPneJvlqijLBfLunAgPsH1V7rvbuk35vZu2a2sOxmBjHe3Q9ltz+RNL7MZgZRcxnvVjptmfG2ee7qWf68UZyg+7Zp7v4DSTMlLc5errYl738P1k5zp0NaxrtVBllm/O/KfO7qXf68UWWEvUdS54D738u2tQV378mueyW9rPZbivrw1yvoZte9Jffzd+20jPdgy4yrDZ67Mpc/LyPs70iaZGZXmtlwSXMkbSmhj28xsxHZiROZ2QhJP1H7LUW9RdL87PZ8Sa+U2Ms3tMsy3nnLjKvk56705c/dveUXSTeq/4z8/0l6pIwecvr6B0l/zi57yu5N0kb1v6w7rv5zGwskXSJpq6QPJL0haWwb9fafknZJek/9wZpQUm/T1P8S/T1JO7PLjWU/d4m+WvK88XFZIAhO0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8PJdJc1jCDmVwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUDbkQ6FwIu9"
      },
      "source": [
        "#one-hot enconding 수행<br>\n",
        "5 --> 0 0 0 0 0 1 0 0 0 0<br>\n",
        "1 --> 0 1 0 0 0 0 0 0 0 0<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEv9hkBBwEJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f665e6-0a15-4c82-dc6f-69311c45be99"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y=y_train, num_classes = 10)\n",
        "ty_train = keras.utils.to_categorical(y=ty_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y=y_test, num_classes=10)\n",
        "y_val = keras.utils.to_categorical(y=y_val, num_classes=10)\n",
        "\n",
        "#리스트 데이타들 출력해 보기\n",
        "for j in range(2):\n",
        "   print(\"\\n=====Y Train Value======\", y_train[j])\n",
        "#end of for\n",
        "\n",
        "for t in range(2):\n",
        "   print(\"\\n=====TY Train Value======\", ty_train[j])\n",
        "#end of for\n",
        "\n",
        "for k in range(2):\n",
        "   print(\"\\n=====Y Test Value======\", y_test[k])\n",
        "#end of for\n",
        "\n",
        "for v in range(2):\n",
        "   print(\"\\n=====Y Val Value======\", y_val[v])\n",
        "#end of for"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Y Train Value====== [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Train Value====== [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfwt_clw7Vt"
      },
      "source": [
        "#DataSet 형변환\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgegW8bww2bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ddf9a4-d3fa-4571-934f-d6c1c0ed2c14"
      },
      "source": [
        "x_train = x_train.reshape(50000, 28*28)\n",
        "tx_train = tx_train.reshape(10000, 28*28)\n",
        "\n",
        "x_test = x_test.reshape(5000, 28*28)\n",
        "x_val = x_val.reshape(5000, 28*28)\n",
        "\n",
        "print(x_train.shape, tx_train.shape,  x_test.shape, x_val.shape)\n",
        "print(y_train.shape, ty_train.shape, y_test.shape, x_val.shape)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (10000, 784) (5000, 784) (5000, 784)\n",
            "(50000, 10) (10000, 10) (5000, 10) (5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP3f4krFIO-N"
      },
      "source": [
        "# https://www.youtube.com/watch?v=UOvPeC8WOt8"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3iM_wFCxmfm"
      },
      "source": [
        "#모델 구조 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYYrPFlxI1i"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\", input_shape=(28*28,)))\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VWPnAlNM17"
      },
      "source": [
        "모델구조 #보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuoRRK3tNWej"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.1), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmnw3IsqyYfc"
      },
      "source": [
        "#모델구성요소 컴파일 및 구조보기\n",
        "<br>파라메터 숫자: \n",
        "<br>dense_3: (28x28) x 32+32(bias) = 25120\n",
        "<br>dense_4: 32x32+32(bias) = 1056\n",
        "<br>dense_5: 32x10+10(bias) = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fpe0OuhyXW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a80af7-57e3-482d-e4aa-040d17fdfebf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_lwPmly8bG"
      },
      "source": [
        "#모델 훈련\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBBANgGMyy-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb974a9-d16a-41e4-f89a-8093116f1672"
      },
      "source": [
        "hist=model.fit(x=x_train, y=y_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 2.2563 - accuracy: 0.2334 - val_loss: 1.9752 - val_accuracy: 0.6330\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.9372 - accuracy: 0.6069 - val_loss: 1.7173 - val_accuracy: 0.7086\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.6876 - accuracy: 0.7006 - val_loss: 1.4497 - val_accuracy: 0.8036\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 1.4379 - accuracy: 0.7633 - val_loss: 1.2058 - val_accuracy: 0.8408\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.2195 - accuracy: 0.8022 - val_loss: 1.0098 - val_accuracy: 0.8594\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.0407 - accuracy: 0.8261 - val_loss: 0.8584 - val_accuracy: 0.8738\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.9067 - accuracy: 0.8421 - val_loss: 0.7538 - val_accuracy: 0.8890\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.8021 - accuracy: 0.8552 - val_loss: 0.6659 - val_accuracy: 0.8992\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.7190 - accuracy: 0.8673 - val_loss: 0.5822 - val_accuracy: 0.9130\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.6539 - accuracy: 0.8740 - val_loss: 0.5367 - val_accuracy: 0.9146\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5975 - accuracy: 0.8822 - val_loss: 0.4846 - val_accuracy: 0.9168\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5557 - accuracy: 0.8841 - val_loss: 0.4501 - val_accuracy: 0.9210\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5206 - accuracy: 0.8892 - val_loss: 0.4268 - val_accuracy: 0.9264\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4977 - accuracy: 0.8915 - val_loss: 0.3937 - val_accuracy: 0.9246\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4654 - accuracy: 0.8963 - val_loss: 0.3747 - val_accuracy: 0.9272\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.8977 - val_loss: 0.3484 - val_accuracy: 0.9312\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4257 - accuracy: 0.9004 - val_loss: 0.3384 - val_accuracy: 0.9290\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.9028 - val_loss: 0.3248 - val_accuracy: 0.9342\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.9050 - val_loss: 0.3283 - val_accuracy: 0.9334\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3796 - accuracy: 0.9090 - val_loss: 0.3021 - val_accuracy: 0.9322\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3711 - accuracy: 0.9089 - val_loss: 0.2947 - val_accuracy: 0.9374\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3677 - accuracy: 0.9084 - val_loss: 0.2907 - val_accuracy: 0.9374\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.9097 - val_loss: 0.2746 - val_accuracy: 0.9378\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3499 - accuracy: 0.9114 - val_loss: 0.2762 - val_accuracy: 0.9378\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3434 - accuracy: 0.9121 - val_loss: 0.2669 - val_accuracy: 0.9388\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3338 - accuracy: 0.9151 - val_loss: 0.2693 - val_accuracy: 0.9384\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3288 - accuracy: 0.9155 - val_loss: 0.2628 - val_accuracy: 0.9374\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.9170 - val_loss: 0.2562 - val_accuracy: 0.9400\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3163 - accuracy: 0.9174 - val_loss: 0.2658 - val_accuracy: 0.9412\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3142 - accuracy: 0.9162 - val_loss: 0.2427 - val_accuracy: 0.9440\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3138 - accuracy: 0.9163 - val_loss: 0.2382 - val_accuracy: 0.9442\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3028 - accuracy: 0.9195 - val_loss: 0.2342 - val_accuracy: 0.9462\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3120 - accuracy: 0.9148 - val_loss: 0.2339 - val_accuracy: 0.9446\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.2970 - accuracy: 0.9203 - val_loss: 0.2367 - val_accuracy: 0.9436\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2947 - accuracy: 0.9205 - val_loss: 0.2189 - val_accuracy: 0.9438\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2870 - accuracy: 0.9220 - val_loss: 0.2283 - val_accuracy: 0.9408\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2933 - accuracy: 0.9210 - val_loss: 0.2218 - val_accuracy: 0.9460\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2786 - accuracy: 0.9241 - val_loss: 0.2144 - val_accuracy: 0.9430\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2827 - accuracy: 0.9237 - val_loss: 0.2299 - val_accuracy: 0.9426\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2804 - accuracy: 0.9238 - val_loss: 0.2241 - val_accuracy: 0.9426\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2757 - accuracy: 0.9239 - val_loss: 0.2353 - val_accuracy: 0.9416\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2863 - accuracy: 0.9211 - val_loss: 0.2125 - val_accuracy: 0.9502\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2716 - accuracy: 0.9251 - val_loss: 0.2203 - val_accuracy: 0.9468\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2701 - accuracy: 0.9257 - val_loss: 0.2191 - val_accuracy: 0.9460\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 0.2626 - accuracy: 0.9282 - val_loss: 0.2139 - val_accuracy: 0.9440\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2606 - accuracy: 0.9293 - val_loss: 0.2100 - val_accuracy: 0.9480\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2654 - accuracy: 0.9272 - val_loss: 0.2158 - val_accuracy: 0.9436\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2608 - accuracy: 0.9274 - val_loss: 0.2034 - val_accuracy: 0.9486\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2562 - accuracy: 0.9304 - val_loss: 0.2014 - val_accuracy: 0.9480\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.9315 - val_loss: 0.2052 - val_accuracy: 0.9498\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2541 - accuracy: 0.9290 - val_loss: 0.1999 - val_accuracy: 0.9512\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2519 - accuracy: 0.9278 - val_loss: 0.1984 - val_accuracy: 0.9470\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2448 - accuracy: 0.9299 - val_loss: 0.1980 - val_accuracy: 0.9506\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2500 - accuracy: 0.9311 - val_loss: 0.1967 - val_accuracy: 0.9494\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2422 - accuracy: 0.9340 - val_loss: 0.2098 - val_accuracy: 0.9420\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.2528 - accuracy: 0.9288 - val_loss: 0.1991 - val_accuracy: 0.9474\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2455 - accuracy: 0.9306 - val_loss: 0.1908 - val_accuracy: 0.9514\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2382 - accuracy: 0.9321 - val_loss: 0.1917 - val_accuracy: 0.9510\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2364 - accuracy: 0.9342 - val_loss: 0.2010 - val_accuracy: 0.9472\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9346 - val_loss: 0.2036 - val_accuracy: 0.9460\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2380 - accuracy: 0.9346 - val_loss: 0.1846 - val_accuracy: 0.9500\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.9338 - val_loss: 0.1903 - val_accuracy: 0.9504\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2428 - accuracy: 0.9305 - val_loss: 0.1809 - val_accuracy: 0.9558\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2313 - accuracy: 0.9344 - val_loss: 0.1906 - val_accuracy: 0.9496\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2388 - accuracy: 0.9321 - val_loss: 0.1961 - val_accuracy: 0.9494\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.2315 - accuracy: 0.9357 - val_loss: 0.1832 - val_accuracy: 0.9528\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 0.9371 - val_loss: 0.1909 - val_accuracy: 0.9506\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.9369 - val_loss: 0.1848 - val_accuracy: 0.9526\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2231 - accuracy: 0.9372 - val_loss: 0.1729 - val_accuracy: 0.9540\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2198 - accuracy: 0.9386 - val_loss: 0.1807 - val_accuracy: 0.9516\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9383 - val_loss: 0.1866 - val_accuracy: 0.9474\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2238 - accuracy: 0.9357 - val_loss: 0.1876 - val_accuracy: 0.9488\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2205 - accuracy: 0.9382 - val_loss: 0.1818 - val_accuracy: 0.9482\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9355 - val_loss: 0.1787 - val_accuracy: 0.9524\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2182 - accuracy: 0.9380 - val_loss: 0.1764 - val_accuracy: 0.9518\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2136 - accuracy: 0.9397 - val_loss: 0.1820 - val_accuracy: 0.9488\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2218 - accuracy: 0.9359 - val_loss: 0.1861 - val_accuracy: 0.9492\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2082 - accuracy: 0.9408 - val_loss: 0.1704 - val_accuracy: 0.9538\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 0.9400 - val_loss: 0.1813 - val_accuracy: 0.9538\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2140 - accuracy: 0.9393 - val_loss: 0.1779 - val_accuracy: 0.9472\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2157 - accuracy: 0.9394 - val_loss: 0.1763 - val_accuracy: 0.9526\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2022 - accuracy: 0.9427 - val_loss: 0.1711 - val_accuracy: 0.9516\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2073 - accuracy: 0.9405 - val_loss: 0.1779 - val_accuracy: 0.9530\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2223 - accuracy: 0.9367 - val_loss: 0.1796 - val_accuracy: 0.9522\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2080 - accuracy: 0.9401 - val_loss: 0.1715 - val_accuracy: 0.9522\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2074 - accuracy: 0.9403 - val_loss: 0.1753 - val_accuracy: 0.9526\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2069 - accuracy: 0.9404 - val_loss: 0.1765 - val_accuracy: 0.9526\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9399 - val_loss: 0.1700 - val_accuracy: 0.9518\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2033 - accuracy: 0.9400 - val_loss: 0.1598 - val_accuracy: 0.9560\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2086 - accuracy: 0.9398 - val_loss: 0.1775 - val_accuracy: 0.9508\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2027 - accuracy: 0.9403 - val_loss: 0.1575 - val_accuracy: 0.9570\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1973 - accuracy: 0.9413 - val_loss: 0.1722 - val_accuracy: 0.9506\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1992 - accuracy: 0.9433 - val_loss: 0.1831 - val_accuracy: 0.9508\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1991 - accuracy: 0.9423 - val_loss: 0.1692 - val_accuracy: 0.9522\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2053 - accuracy: 0.9401 - val_loss: 0.1792 - val_accuracy: 0.9504\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2002 - accuracy: 0.9407 - val_loss: 0.1620 - val_accuracy: 0.9574\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.1909 - accuracy: 0.9441 - val_loss: 0.1646 - val_accuracy: 0.9552\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2048 - accuracy: 0.9410 - val_loss: 0.1622 - val_accuracy: 0.9550\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2157 - accuracy: 0.9372 - val_loss: 0.1745 - val_accuracy: 0.9476\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2026 - accuracy: 0.9410 - val_loss: 0.1533 - val_accuracy: 0.9568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWCAm0xgzmkE"
      },
      "source": [
        "#생성된 모델을 이용한 추론(평가, 예측)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnxTP2eMzRxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9eb943-9124-4322-c7c7-60b593559405"
      },
      "source": [
        "model.evaluate(x_test, y_test )"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.9124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2692508399486542, 0.9124000072479248]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uANcounvIun"
      },
      "source": [
        "#모델 수행 히스토리 그래프보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBbM_KBMDjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c107156d-e2fb-43c1-db96-386f70bca47d"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax =  plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='loss')\n",
        "#loss_ax.plot(hist.history['val_loss'], 'g', label='validation loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='accuracy')\n",
        "#acc_ax.plot(hist.history['val_accuracy'], 'r', label='validation accuracy')\n",
        "\n",
        "plt.legend(['loss', 'accuracy'])\n",
        "#plt.legend(['train loss', 'train accuracy', 'validation loss', 'validation accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmWHScXJQgSE"
      },
      "source": [
        "#모델 바이러리(Weight) 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t44H7KrIQoQe"
      },
      "source": [
        "model.save(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "model.save_weights(\"MNIST-Keras-101-Pre_trained_weights\")"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOQQwtFmRMoJ"
      },
      "source": [
        "#저장된 모델 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cWH_rcCRP7A",
        "outputId": "979b6ba8-a635-4779-8fa4-338de3a0ed8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "ts_model = load_model(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "\n",
        "ts_model.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gum-itSIRQX9"
      },
      "source": [
        "#로드된 모델에 새로운 데이타 Re-Training(Transfer Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za-OTrT4RaSp",
        "outputId": "d2bae36e-0d0e-4ba7-8d15-34dce040a945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist=ts_model.fit(x=tx_train, y=ty_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.2018 - accuracy: 0.9414 - val_loss: 0.1657 - val_accuracy: 0.9548\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2051 - accuracy: 0.9388 - val_loss: 0.1626 - val_accuracy: 0.9568\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9409 - val_loss: 0.1611 - val_accuracy: 0.9558\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2031 - accuracy: 0.9417 - val_loss: 0.1712 - val_accuracy: 0.9502\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2094 - accuracy: 0.9385 - val_loss: 0.1600 - val_accuracy: 0.9560\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1952 - accuracy: 0.9431 - val_loss: 0.1613 - val_accuracy: 0.9558\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1931 - accuracy: 0.9445 - val_loss: 0.1679 - val_accuracy: 0.9518\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.1537 - val_accuracy: 0.9550\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1928 - accuracy: 0.9455 - val_loss: 0.1666 - val_accuracy: 0.9520\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2037 - accuracy: 0.9405 - val_loss: 0.1645 - val_accuracy: 0.9524\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1941 - accuracy: 0.9442 - val_loss: 0.1611 - val_accuracy: 0.9556\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1889 - accuracy: 0.9441 - val_loss: 0.1727 - val_accuracy: 0.9522\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1923 - accuracy: 0.9445 - val_loss: 0.1623 - val_accuracy: 0.9550\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1903 - accuracy: 0.9466 - val_loss: 0.1621 - val_accuracy: 0.9536\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1832 - accuracy: 0.9483 - val_loss: 0.1590 - val_accuracy: 0.9544\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1751 - accuracy: 0.9502 - val_loss: 0.1574 - val_accuracy: 0.9540\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1820 - accuracy: 0.9488 - val_loss: 0.1676 - val_accuracy: 0.9522\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1780 - accuracy: 0.9500 - val_loss: 0.1676 - val_accuracy: 0.9524\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1787 - accuracy: 0.9483 - val_loss: 0.1552 - val_accuracy: 0.9552\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1728 - accuracy: 0.9500 - val_loss: 0.1590 - val_accuracy: 0.9556\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1734 - accuracy: 0.9505 - val_loss: 0.1584 - val_accuracy: 0.9542\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1729 - accuracy: 0.9508 - val_loss: 0.1560 - val_accuracy: 0.9556\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1680 - accuracy: 0.9537 - val_loss: 0.1604 - val_accuracy: 0.9538\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1786 - accuracy: 0.9486 - val_loss: 0.1594 - val_accuracy: 0.9552\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1657 - accuracy: 0.9540 - val_loss: 0.1530 - val_accuracy: 0.9578\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1641 - accuracy: 0.9538 - val_loss: 0.1585 - val_accuracy: 0.9552\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1735 - accuracy: 0.9507 - val_loss: 0.1622 - val_accuracy: 0.9536\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1602 - accuracy: 0.9559 - val_loss: 0.1537 - val_accuracy: 0.9554\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1614 - accuracy: 0.9551 - val_loss: 0.1508 - val_accuracy: 0.9580\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1693 - accuracy: 0.9510 - val_loss: 0.1533 - val_accuracy: 0.9586\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1662 - accuracy: 0.9541 - val_loss: 0.1519 - val_accuracy: 0.9584\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9556 - val_loss: 0.1491 - val_accuracy: 0.9588\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1528 - accuracy: 0.9572 - val_loss: 0.1483 - val_accuracy: 0.9606\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.9582 - val_loss: 0.1558 - val_accuracy: 0.9570\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1603 - accuracy: 0.9559 - val_loss: 0.1541 - val_accuracy: 0.9564\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1576 - accuracy: 0.9558 - val_loss: 0.1555 - val_accuracy: 0.9578\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9580 - val_loss: 0.1535 - val_accuracy: 0.9584\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1508 - accuracy: 0.9590 - val_loss: 0.1573 - val_accuracy: 0.9558\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1536 - accuracy: 0.9566 - val_loss: 0.1543 - val_accuracy: 0.9556\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.1524 - accuracy: 0.9581 - val_loss: 0.1557 - val_accuracy: 0.9534\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1476 - accuracy: 0.9595 - val_loss: 0.1582 - val_accuracy: 0.9542\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.9585 - val_loss: 0.1559 - val_accuracy: 0.9560\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1529 - accuracy: 0.9574 - val_loss: 0.1603 - val_accuracy: 0.9532\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1489 - accuracy: 0.9593 - val_loss: 0.1551 - val_accuracy: 0.9556\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1467 - accuracy: 0.9611 - val_loss: 0.1525 - val_accuracy: 0.9576\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1482 - accuracy: 0.9589 - val_loss: 0.1487 - val_accuracy: 0.9600\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1448 - accuracy: 0.9617 - val_loss: 0.1537 - val_accuracy: 0.9562\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1425 - accuracy: 0.9619 - val_loss: 0.1595 - val_accuracy: 0.9550\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1412 - accuracy: 0.9629 - val_loss: 0.1543 - val_accuracy: 0.9560\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1436 - accuracy: 0.9627 - val_loss: 0.1553 - val_accuracy: 0.9560\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9649 - val_loss: 0.1560 - val_accuracy: 0.9548\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1384 - accuracy: 0.9638 - val_loss: 0.1569 - val_accuracy: 0.9534\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1378 - accuracy: 0.9642 - val_loss: 0.1538 - val_accuracy: 0.9570\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1376 - accuracy: 0.9627 - val_loss: 0.1556 - val_accuracy: 0.9558\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1380 - accuracy: 0.9635 - val_loss: 0.1606 - val_accuracy: 0.9532\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1433 - accuracy: 0.9614 - val_loss: 0.1585 - val_accuracy: 0.9544\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1450 - accuracy: 0.9592 - val_loss: 0.1582 - val_accuracy: 0.9542\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1369 - accuracy: 0.9633 - val_loss: 0.1567 - val_accuracy: 0.9566\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1338 - accuracy: 0.9644 - val_loss: 0.1547 - val_accuracy: 0.9568\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.9653 - val_loss: 0.1513 - val_accuracy: 0.9604\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1294 - accuracy: 0.9657 - val_loss: 0.1496 - val_accuracy: 0.9584\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1262 - accuracy: 0.9677 - val_loss: 0.1509 - val_accuracy: 0.9596\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1308 - accuracy: 0.9656 - val_loss: 0.1541 - val_accuracy: 0.9568\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1311 - accuracy: 0.9648 - val_loss: 0.1526 - val_accuracy: 0.9574\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1299 - accuracy: 0.9654 - val_loss: 0.1488 - val_accuracy: 0.9588\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1327 - accuracy: 0.9662 - val_loss: 0.1514 - val_accuracy: 0.9584\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1290 - accuracy: 0.9664 - val_loss: 0.1591 - val_accuracy: 0.9540\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 0.9657 - val_loss: 0.1548 - val_accuracy: 0.9558\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1285 - accuracy: 0.9665 - val_loss: 0.1532 - val_accuracy: 0.9560\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1303 - accuracy: 0.9660 - val_loss: 0.1516 - val_accuracy: 0.9574\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9655 - val_loss: 0.1474 - val_accuracy: 0.9600\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9676 - val_loss: 0.1532 - val_accuracy: 0.9582\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1274 - accuracy: 0.9673 - val_loss: 0.1510 - val_accuracy: 0.9560\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1277 - accuracy: 0.9667 - val_loss: 0.1486 - val_accuracy: 0.9578\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1279 - accuracy: 0.9677 - val_loss: 0.1470 - val_accuracy: 0.9582\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9669 - val_loss: 0.1521 - val_accuracy: 0.9582\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1258 - accuracy: 0.9675 - val_loss: 0.1538 - val_accuracy: 0.9542\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 0.9673 - val_loss: 0.1470 - val_accuracy: 0.9590\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 0.9672 - val_loss: 0.1503 - val_accuracy: 0.9582\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.9668 - val_loss: 0.1563 - val_accuracy: 0.9554\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1298 - accuracy: 0.9643 - val_loss: 0.1487 - val_accuracy: 0.9596\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1267 - accuracy: 0.9656 - val_loss: 0.1532 - val_accuracy: 0.9574\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1251 - accuracy: 0.9658 - val_loss: 0.1444 - val_accuracy: 0.9602\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1231 - accuracy: 0.9668 - val_loss: 0.1503 - val_accuracy: 0.9582\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1216 - accuracy: 0.9688 - val_loss: 0.1500 - val_accuracy: 0.9576\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1200 - accuracy: 0.9686 - val_loss: 0.1492 - val_accuracy: 0.9576\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1197 - accuracy: 0.9688 - val_loss: 0.1481 - val_accuracy: 0.9584\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1197 - accuracy: 0.9687 - val_loss: 0.1497 - val_accuracy: 0.9584\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1199 - accuracy: 0.9682 - val_loss: 0.1514 - val_accuracy: 0.9564\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1217 - accuracy: 0.9663 - val_loss: 0.1470 - val_accuracy: 0.9594\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1213 - accuracy: 0.9688 - val_loss: 0.1476 - val_accuracy: 0.9582\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1191 - accuracy: 0.9694 - val_loss: 0.1473 - val_accuracy: 0.9598\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1185 - accuracy: 0.9691 - val_loss: 0.1473 - val_accuracy: 0.9572\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1187 - accuracy: 0.9694 - val_loss: 0.1472 - val_accuracy: 0.9584\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1155 - accuracy: 0.9701 - val_loss: 0.1451 - val_accuracy: 0.9584\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1179 - accuracy: 0.9705 - val_loss: 0.1460 - val_accuracy: 0.9588\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1208 - accuracy: 0.9685 - val_loss: 0.1447 - val_accuracy: 0.9584\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.1168 - accuracy: 0.9691 - val_loss: 0.1472 - val_accuracy: 0.9568\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1151 - accuracy: 0.9698 - val_loss: 0.1528 - val_accuracy: 0.9556\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1165 - accuracy: 0.9684 - val_loss: 0.1497 - val_accuracy: 0.9568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctpWPoVVdfT",
        "outputId": "40c5bd82-d9e5-4752-b6f3-de670b1cc81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ts_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.9202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26193633675575256, 0.920199990272522]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    }
  ]
}