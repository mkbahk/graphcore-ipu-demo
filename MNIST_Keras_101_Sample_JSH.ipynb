{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Keras-101-Sample-JSH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7Zu7/tqu4Jk95pg4r656L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbahk/graphcore-ipu-demo/blob/main/MNIST_Keras_101_Sample_JSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7GMXBHQvU7l"
      },
      "source": [
        "#Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Lmu3UgvJoH"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import load_model"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2o6ghk3vgj3"
      },
      "source": [
        "#Load MNIST DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-Zd6MFvnP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ec533b-b4ac-405c-b7f8-9c851b787a9e"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 60000\n",
            "# of y_train 60000\n",
            "# of x_test 10000\n",
            "# of y_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raERFh4uJque"
      },
      "source": [
        "#Transfer Learning 데모를 위한 Training Set 슬라이싱\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpIloZblJzFw",
        "outputId": "0106be88-6b85-4f3b-e1cc-eb2861d32af9"
      },
      "source": [
        "tx_train = x_train[50000:]\n",
        "ty_train = y_train[50000:]\n",
        "\n",
        "x_train = x_train[0:50000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"# of x_train\", len(x_train))\n",
        "print(\"# of y_train\", len(y_train))\n",
        "\n",
        "print(\"# of tx_train\", len(tx_train))\n",
        "print(\"# of ty_train\", len(ty_train))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_train 50000\n",
            "# of y_train 50000\n",
            "# of tx_train 10000\n",
            "# of ty_train 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKMIfSetEwYQ"
      },
      "source": [
        "#ValidationSet을 위한 TestSet 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzz_2UlcE3Se",
        "outputId": "665c4946-6a76-4515-d15e-7bb14ac8353d"
      },
      "source": [
        "x_val = x_test[5000:]\n",
        "y_val = y_test[5000:]\n",
        "\n",
        "x_test = x_test[0:5000]\n",
        "y_test = y_test[0:5000]\n",
        "\n",
        "print(\"# of x_test\", len(x_test))\n",
        "print(\"# of y_test\", len(y_test))\n",
        "\n",
        "print(\"# of x_val\", len(x_val))\n",
        "print(\"# of y_val\", len(y_val))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of x_test 5000\n",
            "# of y_test 5000\n",
            "# of x_val 5000\n",
            "# of y_val 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tklx1amapQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94014e8f-69f4-401a-c8d0-96cd1ce71469"
      },
      "source": [
        "for i in range(5):\n",
        "  print(y_train[i])\n",
        "#end of for"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0\n",
            "4\n",
            "1\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjNWl5tCW9lJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d013a0c-606a-4550-cf77-58747fd48286"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_index = 1 # You may select anything up to 60,000\n",
        "\n",
        "print(x_train[image_index], \"\\n\\n\") # The label is 0\n",
        "print(x_test[image_index], \"\\n\\n\") # The label is 2\n",
        "\n",
        "print(y_train[image_index], \"\\n\\n\")\n",
        "print(y_test[image_index], \"\\n\\n\")\n",
        "\n",
        "print(\"x_train\", x_train.shape, \"x_test\", x_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "print(\"y_train\", y_train.shape, \"y_test\", y_test.shape, \"리스트(배열,행렬)\\n\\n\")\n",
        "\n",
        "\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
            "  159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
            "  252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
            "  233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
            "   84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
            "   96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
            "   47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
            "    0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
            "    0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
            "    0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
            "    0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
            "    7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
            "  131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
            "  252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
            "  162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
            "   56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0\n",
            "    5  20  20  37 150 150 150 147  10   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143\n",
            "  166 253 253 253 253 253 253 253 123   0]\n",
            " [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253\n",
            "  253 253 249 247 247 169 117 117  57   0]\n",
            " [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155\n",
            "  123 123  41   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n",
            "0 \n",
            "\n",
            "\n",
            "2 \n",
            "\n",
            "\n",
            "x_train (50000, 28, 28) x_test (5000, 28, 28) 리스트(배열,행렬)\n",
            "\n",
            "\n",
            "y_train (50000,) y_test (5000,) 리스트(배열,행렬)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc74436f240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUDbkQ6FwIu9"
      },
      "source": [
        "#one-hot enconding 수행<br>\n",
        "5 --> 0 0 0 0 0 1 0 0 0 0<br>\n",
        "1 --> 0 1 0 0 0 0 0 0 0 0<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEv9hkBBwEJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9849d2-9889-4dc8-e6fe-46e2e8da7e34"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y=y_train, num_classes = 10)\n",
        "ty_train = keras.utils.to_categorical(y=ty_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y=y_test, num_classes=10)\n",
        "y_val = keras.utils.to_categorical(y=y_val, num_classes=10)\n",
        "\n",
        "#리스트 데이타들 출력해 보기\n",
        "for j in range(2):\n",
        "   print(\"\\n=====Y Train Value======\", y_train[j])\n",
        "#end of for\n",
        "\n",
        "for t in range(2):\n",
        "   print(\"\\n=====TY Train Value======\", ty_train[j])\n",
        "#end of for\n",
        "\n",
        "for k in range(2):\n",
        "   print(\"\\n=====Y Test Value======\", y_test[k])\n",
        "#end of for\n",
        "\n",
        "for v in range(2):\n",
        "   print(\"\\n=====Y Val Value======\", y_val[v])\n",
        "#end of for"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Y Train Value====== [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Train Value====== [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====TY Train Value====== [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "=====Y Test Value====== [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "=====Y Val Value====== [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfwt_clw7Vt"
      },
      "source": [
        "#DataSet 형변환\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgegW8bww2bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b47c4a-6921-4e88-9d16-ff508669cde9"
      },
      "source": [
        "x_train = x_train.reshape(50000, 28*28)\n",
        "tx_train = tx_train.reshape(10000, 28*28)\n",
        "\n",
        "x_test = x_test.reshape(5000, 28*28)\n",
        "x_val = x_val.reshape(5000, 28*28)\n",
        "\n",
        "print(x_train.shape, tx_train.shape,  x_test.shape, x_val.shape)\n",
        "print(y_train.shape, ty_train.shape, y_test.shape, x_val.shape)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (10000, 784) (5000, 784) (5000, 784)\n",
            "(50000, 10) (10000, 10) (5000, 10) (5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP3f4krFIO-N"
      },
      "source": [
        "# https://www.youtube.com/watch?v=UOvPeC8WOt8"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3iM_wFCxmfm"
      },
      "source": [
        "#모델 구조 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYYrPFlxI1i"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\", input_shape=(28*28,)))\n",
        "model.add(keras.layers.Dense(32, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VWPnAlNM17"
      },
      "source": [
        "모델구조 #보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuoRRK3tNWej"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.1), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmnw3IsqyYfc"
      },
      "source": [
        "#모델구성요소 컴파일 및 구조보기\n",
        "<br>파라메터 숫자: \n",
        "<br>dense_3: (28x28) x 32+32(bias) = 25120\n",
        "<br>dense_4: 32x32+32(bias) = 1056\n",
        "<br>dense_5: 32x10+10(bias) = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fpe0OuhyXW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cce658a-4b8a-4dad-dce9-c94a3a3d7321"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_lwPmly8bG"
      },
      "source": [
        "#모델 훈련\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBBANgGMyy-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f311ea88-fbfd-4c1c-bd80-2d4001c868ac"
      },
      "source": [
        "hist=model.fit(x=x_train, y=y_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 2.2641 - accuracy: 0.2435 - val_loss: 1.9428 - val_accuracy: 0.6548\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.8906 - accuracy: 0.6356 - val_loss: 1.6433 - val_accuracy: 0.7486\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.6094 - accuracy: 0.7078 - val_loss: 1.3673 - val_accuracy: 0.7932\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.3533 - accuracy: 0.7579 - val_loss: 1.1339 - val_accuracy: 0.8366\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.1452 - accuracy: 0.7972 - val_loss: 0.9590 - val_accuracy: 0.8624\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.9872 - accuracy: 0.8219 - val_loss: 0.8172 - val_accuracy: 0.8780\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.8635 - accuracy: 0.8393 - val_loss: 0.7110 - val_accuracy: 0.8948\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.7640 - accuracy: 0.8529 - val_loss: 0.6252 - val_accuracy: 0.9028\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.8626 - val_loss: 0.5695 - val_accuracy: 0.9092\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.8689 - val_loss: 0.5212 - val_accuracy: 0.9066\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.5842 - accuracy: 0.8751 - val_loss: 0.4775 - val_accuracy: 0.9136\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5519 - accuracy: 0.8785 - val_loss: 0.4574 - val_accuracy: 0.9122\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.5252 - accuracy: 0.8796 - val_loss: 0.4213 - val_accuracy: 0.9158\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.8830 - val_loss: 0.4023 - val_accuracy: 0.9210\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4728 - accuracy: 0.8866 - val_loss: 0.3809 - val_accuracy: 0.9190\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4563 - accuracy: 0.8894 - val_loss: 0.3669 - val_accuracy: 0.9212\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4448 - accuracy: 0.8912 - val_loss: 0.3529 - val_accuracy: 0.9240\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4220 - accuracy: 0.8965 - val_loss: 0.3410 - val_accuracy: 0.9240\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.8963 - val_loss: 0.3285 - val_accuracy: 0.9296\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3982 - accuracy: 0.8997 - val_loss: 0.3243 - val_accuracy: 0.9232\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.9000 - val_loss: 0.3117 - val_accuracy: 0.9276\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.9010 - val_loss: 0.3017 - val_accuracy: 0.9274\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.9034 - val_loss: 0.3050 - val_accuracy: 0.9278\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3681 - accuracy: 0.9053 - val_loss: 0.2970 - val_accuracy: 0.9252\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.9060 - val_loss: 0.2804 - val_accuracy: 0.9348\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3536 - accuracy: 0.9062 - val_loss: 0.2779 - val_accuracy: 0.9338\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3491 - accuracy: 0.9079 - val_loss: 0.2657 - val_accuracy: 0.9356\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3330 - accuracy: 0.9114 - val_loss: 0.2919 - val_accuracy: 0.9302\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.9120 - val_loss: 0.2623 - val_accuracy: 0.9340\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.9070 - val_loss: 0.2602 - val_accuracy: 0.9344\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3229 - accuracy: 0.9152 - val_loss: 0.2475 - val_accuracy: 0.9386\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3165 - accuracy: 0.9146 - val_loss: 0.2616 - val_accuracy: 0.9342\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.9169 - val_loss: 0.2525 - val_accuracy: 0.9348\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3060 - accuracy: 0.9178 - val_loss: 0.2533 - val_accuracy: 0.9392\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.9168 - val_loss: 0.2429 - val_accuracy: 0.9386\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.9170 - val_loss: 0.2412 - val_accuracy: 0.9424\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2966 - accuracy: 0.9199 - val_loss: 0.2398 - val_accuracy: 0.9422\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2940 - accuracy: 0.9184 - val_loss: 0.2376 - val_accuracy: 0.9410\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.9194 - val_loss: 0.2408 - val_accuracy: 0.9368\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2921 - accuracy: 0.9216 - val_loss: 0.2302 - val_accuracy: 0.9448\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2862 - accuracy: 0.9212 - val_loss: 0.2217 - val_accuracy: 0.9416\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2794 - accuracy: 0.9229 - val_loss: 0.2282 - val_accuracy: 0.9408\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2859 - accuracy: 0.9207 - val_loss: 0.2299 - val_accuracy: 0.9416\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2829 - accuracy: 0.9193 - val_loss: 0.2282 - val_accuracy: 0.9410\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2787 - accuracy: 0.9213 - val_loss: 0.2322 - val_accuracy: 0.9382\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2826 - accuracy: 0.9205 - val_loss: 0.2425 - val_accuracy: 0.9340\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 0.2820 - accuracy: 0.9203 - val_loss: 0.2172 - val_accuracy: 0.9440\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2684 - accuracy: 0.9250 - val_loss: 0.2256 - val_accuracy: 0.9420\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9220 - val_loss: 0.2192 - val_accuracy: 0.9426\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2759 - accuracy: 0.9235 - val_loss: 0.2196 - val_accuracy: 0.9428\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2633 - accuracy: 0.9265 - val_loss: 0.2249 - val_accuracy: 0.9384\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2640 - accuracy: 0.9243 - val_loss: 0.2073 - val_accuracy: 0.9458\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2516 - accuracy: 0.9280 - val_loss: 0.2038 - val_accuracy: 0.9490\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.9285 - val_loss: 0.2135 - val_accuracy: 0.9416\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2544 - accuracy: 0.9279 - val_loss: 0.2026 - val_accuracy: 0.9466\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2490 - accuracy: 0.9310 - val_loss: 0.2040 - val_accuracy: 0.9446\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2599 - accuracy: 0.9261 - val_loss: 0.1982 - val_accuracy: 0.9482\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2436 - accuracy: 0.9316 - val_loss: 0.2102 - val_accuracy: 0.9414\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2529 - accuracy: 0.9280 - val_loss: 0.2101 - val_accuracy: 0.9450\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2507 - accuracy: 0.9300 - val_loss: 0.1961 - val_accuracy: 0.9450\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.9305 - val_loss: 0.2044 - val_accuracy: 0.9456\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2510 - accuracy: 0.9292 - val_loss: 0.1950 - val_accuracy: 0.9464\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2459 - accuracy: 0.9315 - val_loss: 0.1882 - val_accuracy: 0.9500\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2412 - accuracy: 0.9314 - val_loss: 0.1873 - val_accuracy: 0.9488\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2434 - accuracy: 0.9305 - val_loss: 0.1891 - val_accuracy: 0.9474\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2442 - accuracy: 0.9305 - val_loss: 0.1923 - val_accuracy: 0.9460\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2312 - accuracy: 0.9325 - val_loss: 0.1862 - val_accuracy: 0.9506\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2333 - accuracy: 0.9336 - val_loss: 0.2035 - val_accuracy: 0.9432\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2315 - accuracy: 0.9344 - val_loss: 0.2002 - val_accuracy: 0.9458\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2403 - accuracy: 0.9312 - val_loss: 0.1872 - val_accuracy: 0.9490\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2321 - accuracy: 0.9352 - val_loss: 0.1798 - val_accuracy: 0.9508\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.9355 - val_loss: 0.1956 - val_accuracy: 0.9462\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2286 - accuracy: 0.9333 - val_loss: 0.1937 - val_accuracy: 0.9486\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.9350 - val_loss: 0.1828 - val_accuracy: 0.9508\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.2186 - accuracy: 0.9382 - val_loss: 0.1733 - val_accuracy: 0.9526\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.2206 - accuracy: 0.9359 - val_loss: 0.1817 - val_accuracy: 0.9506\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2235 - accuracy: 0.9351 - val_loss: 0.1833 - val_accuracy: 0.9524\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2262 - accuracy: 0.9336 - val_loss: 0.1882 - val_accuracy: 0.9476\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 0.9354 - val_loss: 0.1851 - val_accuracy: 0.9500\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2245 - accuracy: 0.9366 - val_loss: 0.1777 - val_accuracy: 0.9516\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2233 - accuracy: 0.9364 - val_loss: 0.1793 - val_accuracy: 0.9534\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2219 - accuracy: 0.9361 - val_loss: 0.1852 - val_accuracy: 0.9492\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.2213 - accuracy: 0.9354 - val_loss: 0.1732 - val_accuracy: 0.9502\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.2218 - accuracy: 0.9355 - val_loss: 0.1808 - val_accuracy: 0.9516\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 1s 18ms/step - loss: 0.2143 - accuracy: 0.9381 - val_loss: 0.1889 - val_accuracy: 0.9498\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 0.2209 - accuracy: 0.9356 - val_loss: 0.1823 - val_accuracy: 0.9490\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 0.2153 - accuracy: 0.9363 - val_loss: 0.1797 - val_accuracy: 0.9508\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.2195 - accuracy: 0.9369 - val_loss: 0.1683 - val_accuracy: 0.9550\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.2166 - accuracy: 0.9381 - val_loss: 0.1846 - val_accuracy: 0.9484\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2158 - accuracy: 0.9363 - val_loss: 0.1679 - val_accuracy: 0.9536\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2135 - accuracy: 0.9392 - val_loss: 0.1819 - val_accuracy: 0.9520\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2116 - accuracy: 0.9398 - val_loss: 0.1793 - val_accuracy: 0.9530\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2149 - accuracy: 0.9384 - val_loss: 0.1743 - val_accuracy: 0.9520\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2142 - accuracy: 0.9388 - val_loss: 0.1782 - val_accuracy: 0.9506\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2159 - accuracy: 0.9361 - val_loss: 0.1715 - val_accuracy: 0.9506\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2067 - accuracy: 0.9404 - val_loss: 0.1770 - val_accuracy: 0.9494\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2090 - accuracy: 0.9383 - val_loss: 0.1679 - val_accuracy: 0.9552\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2075 - accuracy: 0.9407 - val_loss: 0.1570 - val_accuracy: 0.9568\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.2015 - accuracy: 0.9409 - val_loss: 0.1545 - val_accuracy: 0.9570\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.1986 - accuracy: 0.9436 - val_loss: 0.1635 - val_accuracy: 0.9536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWCAm0xgzmkE"
      },
      "source": [
        "#생성된 모델을 이용한 추론(평가, 예측)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnxTP2eMzRxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93bc690-dd01-41f4-b8cb-e1f5e62261f1"
      },
      "source": [
        "model.evaluate(x_test, y_test )"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.9176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27187010645866394, 0.9175999760627747]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uANcounvIun"
      },
      "source": [
        "#모델 수행 히스토리 그래프보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBbM_KBMDjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5c6442d7-cb81-4a39-b450-2978797ac6ab"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax =  plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='loss')\n",
        "#loss_ax.plot(hist.history['val_loss'], 'g', label='validation loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='accuracy')\n",
        "#acc_ax.plot(hist.history['val_accuracy'], 'r', label='validation accuracy')\n",
        "\n",
        "plt.legend(['loss', 'accuracy'])\n",
        "#plt.legend(['train loss', 'train accuracy', 'validation loss', 'validation accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmWHScXJQgSE"
      },
      "source": [
        "#모델 바이러리(Weight) 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t44H7KrIQoQe"
      },
      "source": [
        "model.save(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "model.save_weights(\"MNIST-Keras-101-Pre_trained_weights\")"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOQQwtFmRMoJ"
      },
      "source": [
        "#저장된 모델 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cWH_rcCRP7A",
        "outputId": "3995f81b-f5b3-4bc5-c81e-41d9e6d96692"
      },
      "source": [
        "\n",
        "ts_model = load_model(\"MNIST-Keras-101-Pre_trained.h5\")\n",
        "ts_model.summary()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gum-itSIRQX9"
      },
      "source": [
        "#로드된 모델에 새로운 데이타 Re-Training(Transfer Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za-OTrT4RaSp",
        "outputId": "f55f1653-31e5-4281-9301-8d165957c88e"
      },
      "source": [
        "hist=ts_model.fit(x=tx_train, y=ty_train, batch_size=1000, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.2147 - accuracy: 0.9379 - val_loss: 0.1684 - val_accuracy: 0.9514\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2193 - accuracy: 0.9353 - val_loss: 0.1741 - val_accuracy: 0.9516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2135 - accuracy: 0.9371 - val_loss: 0.1749 - val_accuracy: 0.9504\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2174 - accuracy: 0.9370 - val_loss: 0.1682 - val_accuracy: 0.9538\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2017 - accuracy: 0.9408 - val_loss: 0.1615 - val_accuracy: 0.9564\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2006 - accuracy: 0.9410 - val_loss: 0.1681 - val_accuracy: 0.9496\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2055 - accuracy: 0.9401 - val_loss: 0.1688 - val_accuracy: 0.9504\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1935 - accuracy: 0.9445 - val_loss: 0.1648 - val_accuracy: 0.9552\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1935 - accuracy: 0.9456 - val_loss: 0.1571 - val_accuracy: 0.9564\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1934 - accuracy: 0.9457 - val_loss: 0.1622 - val_accuracy: 0.9528\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1874 - accuracy: 0.9474 - val_loss: 0.1573 - val_accuracy: 0.9532\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1906 - accuracy: 0.9451 - val_loss: 0.1579 - val_accuracy: 0.9568\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1921 - accuracy: 0.9436 - val_loss: 0.1734 - val_accuracy: 0.9484\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1997 - accuracy: 0.9413 - val_loss: 0.1718 - val_accuracy: 0.9506\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1950 - accuracy: 0.9432 - val_loss: 0.1629 - val_accuracy: 0.9532\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1924 - accuracy: 0.9464 - val_loss: 0.1641 - val_accuracy: 0.9524\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1849 - accuracy: 0.9460 - val_loss: 0.1648 - val_accuracy: 0.9548\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9484 - val_loss: 0.1715 - val_accuracy: 0.9500\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1841 - accuracy: 0.9462 - val_loss: 0.1641 - val_accuracy: 0.9520\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9479 - val_loss: 0.1709 - val_accuracy: 0.9484\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1814 - accuracy: 0.9467 - val_loss: 0.1648 - val_accuracy: 0.9536\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1766 - accuracy: 0.9519 - val_loss: 0.1663 - val_accuracy: 0.9520\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1733 - accuracy: 0.9525 - val_loss: 0.1661 - val_accuracy: 0.9534\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1742 - accuracy: 0.9509 - val_loss: 0.1616 - val_accuracy: 0.9540\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1747 - accuracy: 0.9523 - val_loss: 0.1668 - val_accuracy: 0.9552\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9479 - val_loss: 0.1637 - val_accuracy: 0.9556\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1706 - accuracy: 0.9520 - val_loss: 0.1633 - val_accuracy: 0.9508\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1738 - accuracy: 0.9516 - val_loss: 0.1687 - val_accuracy: 0.9508\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1674 - accuracy: 0.9524 - val_loss: 0.1633 - val_accuracy: 0.9516\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1737 - accuracy: 0.9497 - val_loss: 0.1512 - val_accuracy: 0.9568\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9534 - val_loss: 0.1583 - val_accuracy: 0.9546\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1738 - accuracy: 0.9510 - val_loss: 0.1657 - val_accuracy: 0.9536\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1638 - accuracy: 0.9535 - val_loss: 0.1556 - val_accuracy: 0.9554\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1595 - accuracy: 0.9576 - val_loss: 0.1581 - val_accuracy: 0.9550\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1609 - accuracy: 0.9562 - val_loss: 0.1564 - val_accuracy: 0.9572\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1611 - accuracy: 0.9567 - val_loss: 0.1585 - val_accuracy: 0.9564\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 0.9567 - val_loss: 0.1639 - val_accuracy: 0.9534\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1573 - accuracy: 0.9562 - val_loss: 0.1624 - val_accuracy: 0.9556\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1632 - accuracy: 0.9544 - val_loss: 0.1658 - val_accuracy: 0.9544\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1609 - accuracy: 0.9560 - val_loss: 0.1588 - val_accuracy: 0.9560\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1604 - accuracy: 0.9550 - val_loss: 0.1642 - val_accuracy: 0.9536\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.1654 - accuracy: 0.9545 - val_loss: 0.1664 - val_accuracy: 0.9530\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1643 - accuracy: 0.9549 - val_loss: 0.1672 - val_accuracy: 0.9528\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1608 - accuracy: 0.9567 - val_loss: 0.1632 - val_accuracy: 0.9556\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.9565 - val_loss: 0.1712 - val_accuracy: 0.9480\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1581 - accuracy: 0.9556 - val_loss: 0.1585 - val_accuracy: 0.9532\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1519 - accuracy: 0.9583 - val_loss: 0.1545 - val_accuracy: 0.9574\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1552 - accuracy: 0.9581 - val_loss: 0.1597 - val_accuracy: 0.9538\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1524 - accuracy: 0.9577 - val_loss: 0.1584 - val_accuracy: 0.9548\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1509 - accuracy: 0.9590 - val_loss: 0.1503 - val_accuracy: 0.9546\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.9577 - val_loss: 0.1538 - val_accuracy: 0.9544\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1458 - accuracy: 0.9603 - val_loss: 0.1537 - val_accuracy: 0.9542\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1451 - accuracy: 0.9611 - val_loss: 0.1561 - val_accuracy: 0.9554\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1430 - accuracy: 0.9615 - val_loss: 0.1534 - val_accuracy: 0.9578\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1464 - accuracy: 0.9605 - val_loss: 0.1588 - val_accuracy: 0.9548\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1442 - accuracy: 0.9605 - val_loss: 0.1574 - val_accuracy: 0.9566\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1449 - accuracy: 0.9597 - val_loss: 0.1540 - val_accuracy: 0.9566\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1442 - accuracy: 0.9597 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1437 - accuracy: 0.9596 - val_loss: 0.1611 - val_accuracy: 0.9526\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1451 - accuracy: 0.9594 - val_loss: 0.1585 - val_accuracy: 0.9568\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1449 - accuracy: 0.9597 - val_loss: 0.1563 - val_accuracy: 0.9548\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1485 - accuracy: 0.9578 - val_loss: 0.1672 - val_accuracy: 0.9522\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1432 - accuracy: 0.9597 - val_loss: 0.1583 - val_accuracy: 0.9542\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 0.9624 - val_loss: 0.1557 - val_accuracy: 0.9540\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1378 - accuracy: 0.9620 - val_loss: 0.1561 - val_accuracy: 0.9540\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9627 - val_loss: 0.1596 - val_accuracy: 0.9544\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1422 - accuracy: 0.9609 - val_loss: 0.1589 - val_accuracy: 0.9522\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9612 - val_loss: 0.1557 - val_accuracy: 0.9552\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1373 - accuracy: 0.9615 - val_loss: 0.1586 - val_accuracy: 0.9534\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1351 - accuracy: 0.9627 - val_loss: 0.1542 - val_accuracy: 0.9542\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1358 - accuracy: 0.9633 - val_loss: 0.1565 - val_accuracy: 0.9538\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1425 - accuracy: 0.9607 - val_loss: 0.1552 - val_accuracy: 0.9560\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1417 - accuracy: 0.9620 - val_loss: 0.1567 - val_accuracy: 0.9534\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1368 - accuracy: 0.9620 - val_loss: 0.1555 - val_accuracy: 0.9552\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1312 - accuracy: 0.9641 - val_loss: 0.1518 - val_accuracy: 0.9562\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1289 - accuracy: 0.9639 - val_loss: 0.1525 - val_accuracy: 0.9550\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1280 - accuracy: 0.9639 - val_loss: 0.1547 - val_accuracy: 0.9526\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1276 - accuracy: 0.9652 - val_loss: 0.1575 - val_accuracy: 0.9536\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1369 - accuracy: 0.9595 - val_loss: 0.1608 - val_accuracy: 0.9532\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1325 - accuracy: 0.9617 - val_loss: 0.1552 - val_accuracy: 0.9546\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1310 - accuracy: 0.9644 - val_loss: 0.1540 - val_accuracy: 0.9546\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1320 - accuracy: 0.9648 - val_loss: 0.1590 - val_accuracy: 0.9532\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9626 - val_loss: 0.1596 - val_accuracy: 0.9526\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9639 - val_loss: 0.1569 - val_accuracy: 0.9560\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1301 - accuracy: 0.9644 - val_loss: 0.1568 - val_accuracy: 0.9554\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1281 - accuracy: 0.9661 - val_loss: 0.1543 - val_accuracy: 0.9534\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1251 - accuracy: 0.9657 - val_loss: 0.1551 - val_accuracy: 0.9522\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1216 - accuracy: 0.9680 - val_loss: 0.1492 - val_accuracy: 0.9552\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1217 - accuracy: 0.9671 - val_loss: 0.1480 - val_accuracy: 0.9558\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1189 - accuracy: 0.9679 - val_loss: 0.1491 - val_accuracy: 0.9560\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1227 - accuracy: 0.9675 - val_loss: 0.1511 - val_accuracy: 0.9554\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1202 - accuracy: 0.9674 - val_loss: 0.1497 - val_accuracy: 0.9546\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1154 - accuracy: 0.9689 - val_loss: 0.1523 - val_accuracy: 0.9532\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1157 - accuracy: 0.9690 - val_loss: 0.1500 - val_accuracy: 0.9546\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1154 - accuracy: 0.9693 - val_loss: 0.1481 - val_accuracy: 0.9552\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1175 - accuracy: 0.9675 - val_loss: 0.1534 - val_accuracy: 0.9550\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1207 - accuracy: 0.9658 - val_loss: 0.1505 - val_accuracy: 0.9562\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1160 - accuracy: 0.9674 - val_loss: 0.1514 - val_accuracy: 0.9574\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.1502 - val_accuracy: 0.9568\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.1140 - accuracy: 0.9695 - val_loss: 0.1472 - val_accuracy: 0.9592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kctpWPoVVdfT",
        "outputId": "90c5bf89-b8a4-48c4-a7fa-06d94c85924d"
      },
      "source": [
        "ts_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2554292380809784, 0.9210000038146973]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKfJLRG0XFJm"
      },
      "source": [
        "model.save(\"MNIST-Keras-101-Transfer_learned.h5\")\n",
        "model.save_weights(\"MNIST-Keras-101-Transfer_learned_weights\")"
      ],
      "execution_count": 191,
      "outputs": []
    }
  ]
}