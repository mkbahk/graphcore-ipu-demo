{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "CTScans-cnn-keras-functional-cpu-dist.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTRalcg7kkcJ"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM1X_SyDkkcj"
      },
      "source": [
        "# Download url of normal CT scans.\n",
        "#url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "#filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "#keras.utils.get_file(filename, url)\n",
        "\n",
        "# Download url of abnormal CT scans.\n",
        "#url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "#filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "#keras.utils.get_file(filename, url)\n",
        "\n",
        "# Make a directory to store the data.\n",
        "if not os.path.exists(\"./MosMedData\"):\n",
        "    os.makedirs(\"MosMedData\")\n",
        "\n",
        "    # Unzip data in the newly created directory.\n",
        "    with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "        z_fp.extractall(\"./MosMedData/\")\n",
        "    #end of with\n",
        "\n",
        "    with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "        z_fp.extractall(\"./MosMedData/\")\n",
        "    #end of with\n",
        "#end of if"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fO0Wnsqkkck"
      },
      "source": [
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "\n",
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "#end of def\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "#end of def\n",
        "\n",
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "#end of def\n",
        "\n",
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    volume = resize_volume(volume)\n",
        "    return volume\n",
        "#end of def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2oMUQAkkcl"
      },
      "source": [
        "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
        "# no CT-signs of viral pneumonia.\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-0\")\n",
        "]\n",
        "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
        "# involvement of lung parenchyma.\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-23\")\n",
        "]\n",
        "\n",
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))\n",
        "\n",
        "start = time.time() # ?��?�� ?���? ????��\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hNv4I7zkkcm"
      },
      "source": [
        "# 작업시간 오래 걸립니다. 약 10분...\n",
        "# Each scan is resized across height, width, and depth and rescaled.\n",
        "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "\n",
        "# For the CT scans having presence of viral pneumonia\n",
        "# assign 1, for the normal ones assign 0.\n",
        "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
        "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
        "\n",
        "# Split data in the ratio 70-30 for training and validation.\n",
        "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
        "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
        "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
        "print(\n",
        "    \"Number of samples in train and validation are %d and %d.\"\n",
        "    % (x_train.shape[0], x_val.shape[0])\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTLgztlJkkcn"
      },
      "source": [
        "import random\n",
        "from scipy import ndimage\n",
        "\n",
        "@tf.function\n",
        "def rotate(volume):\n",
        "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "    #end of def\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "#end of def\n",
        "\n",
        "def train_preprocessing(volume, label):\n",
        "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
        "    # Rotate volume\n",
        "    volume = rotate(volume)\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "#end of def\n",
        "\n",
        "def validation_preprocessing(volume, label):\n",
        "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "#end of def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-xcy_8kkcp"
      },
      "source": [
        "# Define data loaders.\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "\n",
        "batch_size = 2\n",
        "# Augment the on the fly during training.\n",
        "train_dataset = (\n",
        "    train_loader.shuffle(len(x_train))\n",
        "    .map(train_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")\n",
        "\n",
        "# Only rescale.\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(x_val))\n",
        "    .map(validation_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgnw5jI_kkcp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = train_dataset.take(1)\n",
        "images, labels = list(data)[0]\n",
        "images = images.numpy()\n",
        "image = images[0]\n",
        "print(\"Dimension of the CT scan is:\", image.shape)\n",
        "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e7tp3dhkkcq"
      },
      "source": [
        "def plot_slices(num_rows, num_columns, width, height, data):\n",
        "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
        "    data = np.rot90(np.array(data))\n",
        "    data = np.transpose(data)\n",
        "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
        "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
        "    heights = [slc[0].shape[0] for slc in data]\n",
        "    widths = [slc.shape[1] for slc in data[0]]\n",
        "    fig_width = 12.0\n",
        "    fig_height = fig_width * sum(heights) / sum(widths)\n",
        "    f, axarr = plt.subplots(\n",
        "        rows_data,\n",
        "        columns_data,\n",
        "        figsize=(fig_width, fig_height),\n",
        "        gridspec_kw={\"height_ratios\": heights},\n",
        "    )\n",
        "    for i in range(rows_data):\n",
        "        for j in range(columns_data):\n",
        "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
        "            axarr[i, j].axis(\"off\")\n",
        "        #end of for\n",
        "    #end of for\n",
        "    \n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "#end of def\n",
        "\n",
        "# Visualize montage of slices.\n",
        "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
        "plot_slices(4, 10, 128, 128, image[:, :, :40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8csWGn6kkcv"
      },
      "source": [
        "def get_model(width=128, height=128, depth=64):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "#end of def\n",
        "\n",
        "# Build model.\n",
        "model = get_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrkLwigTkkc3"
      },
      "source": [
        "# Compile model.\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "\n",
        "# Define callbacks.\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"3d_image_classification.h5\", save_best_only=True\n",
        ")\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch\n",
        "epochs = 100\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ2eTZ4vkkc3"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
        "    ax[i].plot(model.history.history[metric])\n",
        "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])\n",
        "#end of for\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfu9jp8Lkkc4"
      },
      "source": [
        "# Load best weights.\n",
        "model.load_weights(\"3d_image_classification.h5\")\n",
        "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"abnormal\"]\n",
        "\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"This model is %.2f percent confident that CT scan is %s\"\n",
        "        % ((100 * score), name)\n",
        "    )\n",
        "#end of for"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}