{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mkbahk/graphcore-ipu-demo/blob/main/mnist-dnn-keras-functional-cpu-input-and-output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "FpvUOuC3j27n"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "HCGy1S8_mPnV"
   },
   "outputs": [],
   "source": [
    "start = time.time() # 시작 시간 저장\r\n",
    "strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "nHDDw4H8c2qJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# The input data and labels.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train, x_test) = (x_train / 255.0, x_test / 255.0)\n",
    "\n",
    "# Add a channels dimension.\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "print(x_train.shape)\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "eKKTURm8c5jP"
   },
   "outputs": [],
   "source": [
    "def create_train_dataset():\n",
    "    print(\"==============================Processing Training DataSet==============================\\n\\n\")\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(32, drop_remainder=True)\n",
    "    print(train_ds)\n",
    "    train_ds = train_ds.map(lambda data, label: (tf.cast(data, tf.float32), tf.cast(label, tf.float32)))\n",
    "    print(train_ds)\n",
    "    return train_ds.repeat()\n",
    "#end of def\n",
    "\n",
    "def create_test_dataset():\n",
    "    print(\"==============================Processing Test  DataSet==============================\\n\\n\")\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(10000).batch(32, drop_remainder=True)\n",
    "    print(test_ds)\n",
    "    test_ds = test_ds.map(lambda data, label: (tf.cast(data, tf.float32), tf.cast(label, tf.float32)))\n",
    "    print(test_ds)\n",
    "    return test_ds.repeat()\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "fuP7KABnc8rV"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (28, 28))\n",
    "    \n",
    "    flatten_layer = keras.layers.Lambda(lambda ipt: K.reshape(ipt, (-1, 28 * 28)))\n",
    "    flattened_input = flatten_layer(inputs)\n",
    "\n",
    "    x = keras.layers.Flatten()(flattened_input)   \n",
    "    x = keras.layers.Dense(128, activation='relu')(x) \n",
    "    x = keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    # Defined the model.\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"dnn\")\n",
    "    \n",
    "    model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   optimizer = tf.keras.optimizers.Adam(), \n",
    "#                  steps_per_execution = 50, \n",
    "                   metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "Jw6kNn_kc_IK"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "      # Get the training dataset.\n",
    "      print(\"==============================Getting Training DataSet=================================\\n\\n\")\n",
    "      ds1 = create_train_dataset()\n",
    "      print(\"==============================Getting Test DataSet====================================\\n\\n\")\n",
    "      ds2 = create_test_dataset()\n",
    "\n",
    "      with strategy.scope():   \n",
    "           # Create an instance of the model.\n",
    "           print(\"==============================Building Model====================================\\n\\n\")\n",
    "           model = create_model()\n",
    "\n",
    "           model.summary()\n",
    "\n",
    "           print(\"==============================Building Compile====================================\\n\\n\")      \n",
    "\n",
    "        \n",
    "           print(\"==============================Model Training ====================================\\n\\n\")\n",
    "           model.fit(ds1, steps_per_epoch=2000, epochs=50)\n",
    "\n",
    "           print(\"\\n\\n==============================Checking the result==============================\\n\\n\")\n",
    "           (loss, accuracy) = model.evaluate(ds2, steps=1000)\n",
    "        \n",
    "           print(\"Validation loss: {}\".format(loss))\n",
    "           print(\"Validation accuracy: {}%\".format(100.0 * accuracy))\n",
    "           print(\"\\n\\n==============================Job Done====================================\")\n",
    "      #end of with\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "08N38eYodElH",
    "outputId": "b4afdca2-81a1-4fb8-b7c8-72d820a9ea1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================Getting Training DataSet=================================\n",
      "\n",
      "\n",
      "==============================Processing Training DataSet==============================\n",
      "\n",
      "\n",
      "<BatchDataset shapes: ((32, 28, 28, 1), (32,)), types: (tf.float64, tf.uint8)>\n",
      "<MapDataset shapes: ((32, 28, 28, 1), (32,)), types: (tf.float32, tf.float32)>\n",
      "==============================Getting Test DataSet====================================\n",
      "\n",
      "\n",
      "==============================Processing Test  DataSet==============================\n",
      "\n",
      "\n",
      "<BatchDataset shapes: ((32, 28, 28, 1), (32,)), types: (tf.float64, tf.uint8)>\n",
      "<MapDataset shapes: ((32, 28, 28, 1), (32,)), types: (tf.float32, tf.float32)>\n",
      "==============================Building Model====================================\n",
      "\n",
      "\n",
      "Model: \"dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 167,690\n",
      "Trainable params: 167,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "==============================Building Compile====================================\n",
      "\n",
      "\n",
      "==============================Model Training ====================================\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9368\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9798\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0412 - sparse_categorical_accuracy: 0.9871\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9887\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9922\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9935\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9946\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9942\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9953\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0139 - sparse_categorical_accuracy: 0.995 - 6s 3ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9952\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9959\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9957\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9971\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9964\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9964\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9977\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9973\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9975\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9977\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9977\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9973\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9978\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9975\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9983\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9977\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9984\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9975\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9984\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9977\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9985\n",
      "\n",
      "\n",
      "==============================Checking the result==============================\n",
      "\n",
      "\n",
      "1000/1000 [==============================] - 1s 862us/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9811\n",
      "Validation loss: 0.2089485377073288\n",
      "Validation accuracy: 98.10937643051147%\n",
      "\n",
      "\n",
      "==============================Job Done====================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "#end of if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "xsAhmmdbdhg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행시간 : 318.5923638343811 (초)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Execution Time :\", time.time() - start,\"(Sec)\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist-tpu-dist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
