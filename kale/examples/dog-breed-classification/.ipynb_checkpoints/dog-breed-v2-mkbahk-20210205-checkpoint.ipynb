{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dog Breed Classification\n",
    "\n",
    "This example is based on a very popular [Udacity project](https://github.com/udacity/dog-project), upgraded to use TensorFlow `2.3.0` with GPU accelaration. The goal is to classify images of dogs according to their breed.\n",
    "\n",
    "In this notebook, we take the first steps towards developing an algorithm that could be used as part of a mobile or web app. At the end of this project, our code will accept any user-supplied image as input. If a dog is detected in the image, it will provide an estimate of the dog's breed. In this real-world setting, we will piece together a series of state-of-the-art computer vision models to perform different tasks (Dog detection -> Breed classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of contents\n",
    "\n",
    "We break the notebook into separate steps. Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Download Datasets and Install Dependencies\n",
    "* [Step 1](#step1): Import Datasets\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Create a CNN (VGG16) to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Create a CNN (ResNet-50) to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 6](#step6): Write your Own Dog Classifier\n",
    "* [Step 7](#step7): Test Your Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvAyLIR-R0af",
    "tags": []
   },
   "source": [
    "<a id='step0'></a>\n",
    "## Step 0: Download Datasets and Install Dependencies\n",
    "\n",
    "For this task we use TensorFlow `2.3.0`, as well as a few helper libraries like `Pillow`. Also, we need to download and extract the dataset we will use to train our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fm1cOPKZSJQB",
    "tags": []
   },
   "source": [
    "### Download the dataset\n",
    "\n",
    "The dataset is available [here](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip). The following cell downloads it as a zip file, extracts it and moves it to the corresponding folder. Finally, it removes the `zip` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOpDJZCQGRb",
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-05 03:32:20--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.113.40\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.113.40|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1132023110 (1.1G) [application/zip]\n",
      "Saving to: 'dogImages.zip'\n",
      "\n",
      "dogImages.zip       100%[===================>]   1.05G  10.1MB/s    in 2m 33s  \n",
      "\n",
      "2021-02-05 03:34:53 (7.06 MB/s) - 'dogImages.zip' saved [1132023110/1132023110]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip -qo dogImages.zip\n",
    "!rm dogImages.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3iHERkNSNY-",
    "tags": []
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "The task requires `Pillow` the friendly PIL fork by [Alex Clark and Contributors](https://github.com/python-pillow/Pillow/graphs/contributors). PIL is the Python Imaging Library by Fredrik Lundh and Contributors. Below, we install the `Pillow` package using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WU7JZLVSRyAT",
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow==7.2.0\n",
      "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |################################| 2.2 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |################################| 320.4 MB 56 kB/s s eta 0:00:01    |#                               | 11.3 MB 10.6 MB/s eta 0:00:30     |##############                  | 142.7 MB 10.3 MB/s eta 0:00:18     |###################             | 191.7 MB 10.5 MB/s eta 0:00:13     |###################             | 194.6 MB 12.0 MB/s eta 0:00:11     |###################             | 197.5 MB 12.0 MB/s eta 0:00:11     |####################            | 204.5 MB 12.0 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting matplotlib==3.3.1\n",
      "  Downloading matplotlib-3.3.1-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |################################| 11.6 MB 1.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from matplotlib==3.3.1->-r requirements/requirements-v2.txt (line 3)) (0.10.0)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |################################| 26.1 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |################################| 459 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.14.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.32.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.3.3)\n",
      "Collecting numpy>=1.15\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |################################| 20.1 MB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.24.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (51.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mkbahk/venvcputf24/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements/requirements-v2.txt (line 2)) (3.4.0)\n",
      "Installing collected packages: numpy, tensorflow-estimator, scipy, pillow, tensorflow, matplotlib\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.1.0\n",
      "    Uninstalling Pillow-8.1.0:\n",
      "      Successfully uninstalled Pillow-8.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.0\n",
      "    Uninstalling tensorflow-2.4.0:\n",
      "      Successfully uninstalled tensorflow-2.4.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --user -r requirements/requirements-v2.txt\n",
    "!pip3 install -r requirements/requirements-v2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67p9fU72SQE9",
    "tags": []
   },
   "source": [
    "### Import the necessary libraries\n",
    "\n",
    "We use Tensorflow `2.3.0` to build and train our dog breed classifier. We also need `Pillow` to load the images in memory, which we specifically instruct to load any truncated images also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X11SD82SUhb",
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKq8rHg5SWXq",
    "outputId": "7056f7a7-d327-4622-a59a-32b2108977f4",
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Version of TensorFlow in use: {tf.__version__}\")\n",
    "print(f\"Using GPU device: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ac4gM-_KSkV4",
    "tags": []
   },
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Import Datasets\n",
    "\n",
    "First, let us define the pipeline-parameters cell. We use it to define the hyperparametes we would like to tune later. These variables will be converted to KFP pipeline parameters, so we should make sure they are used as global variables throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifMA-P1ySYK2",
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "LR = 6e-4\n",
    "BATCH_SIZE = 32\n",
    "NUMBER_OF_NODES = 256\n",
    "EPOCHS = 4\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsWsiKbhTN4E",
    "tags": []
   },
   "source": [
    "### Processing the Dataset\n",
    "\n",
    "We use TensorFlow native generators to load and transform the data. Pay attention to the `train_datagen` which also includes several transformations to augment our dataset (e.g. width and height shift, brightness alterations and horizontal flip). These transformations are taking place in memory, leaving the original data untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:data_processing"
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_generator():\n",
    "    data_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range=.2,\n",
    "        height_shift_range=.2,\n",
    "        brightness_range=[0.5,1.5],\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    return data_datagen.flow_from_directory(\n",
    "        \"dogImages/train/\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        \n",
    "    )\n",
    "#end of def\n",
    "\n",
    "def get_valid_generator():\n",
    "    data_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return data_datagen.flow_from_directory(\n",
    "        \"dogImages/valid/\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "#end of def\n",
    "\n",
    "def get_test_generator():\n",
    "    data_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return data_datagen.flow_from_directory(\n",
    "        \"dogImages/test/\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r021ns1ZUzi4",
    "tags": []
   },
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a pre-trained [ResNet V2](https://link.springer.com/chapter/10.1007/978-3-319-46493-0_38) model to detect dogs in images. First, we download a pretrained ResNet-50 model on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other computer vision tasks. ImageNet contains over 10 million URLs, each linking to an image containing an object from one of 1000 categories. Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgWSAhN-TFNf",
    "tags": [
     "block:dog_detector",
     "prev:data_processing",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "dog_classifier = tf.keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The categories corresponding to dogs appear in an uninterrupted sequence referring to dictionary keys 151-268, inclusive, to include all categories from 'Chihuahua' to 'Mexican hairless'. Thus, in order to check if an image is predicted to contain a dog by the pre-trained ResNet model, we need only check if the function below returns a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to complete the `is_dog` function below, which returns True if a dog is detected in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lguOZx_PWE73",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_dog(data):\n",
    "    probs = dog_classifier.predict(data)\n",
    "    preds = tf.argmax(probs, axis=1)\n",
    "    return ((preds >= 151) & (preds <= 268))\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To test the classifier we request a batch from our training data generator and feed it through the network. The accuracy, as expected, is really high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AkKSHeaYIcg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = get_train_generator()\n",
    "batch = train_generator.next()\n",
    "predictions = is_dog(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wGeUt1jidjat",
    "outputId": "19f96954-ed31-4ab5-917a-53178f696e10",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_dog = np.sum(predictions)\n",
    "dog_percentage = n_dog/BATCH_SIZE\n",
    "\n",
    "print('{:.0%} of the files have a detected dog'.format(dog_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WJ6MCYrf4sR",
    "tags": []
   },
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have a function for detecting dogs in images, we need a way to predict the dog breed from images. In this step, you will create a CNN that classifies dog breeds. We should be careful with adding too many trainable layers though. More parameters means longer training and you may also fall in the trap of overfitting. Thankfully, `tf.keras` provides a handy estimate of the time that each epoch is likely to take; you can extrapolate this estimate to figure out how long it will take for your algorithm to train.\n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging. To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black. Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador  \n",
    "- | - | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing `model.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cX4dZkEjfe6u",
    "tags": [
     "block:custom_classifier",
     "prev:data_processing",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(NUMBER_OF_NODES, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(133, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "iMmibLNahFRp",
    "outputId": "31a84afd-576e-4262-efea-978fd98d0255",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The next step is to compile the model. For this, we need to pass an optimizer and a loss function. We can also pass a list of metrics we want. In this example, we pass the _accuracy_ metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uRX3_UyhN90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=LR),\n",
    "    loss=tf.losses.categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we can train the model using the `fit` method. This runs on batches yielded by the data generator and prints out the _loss_ and _accuracy_ both for train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Vj67Ok9dhbOC",
    "outputId": "2e64d6cf-0c21-4fac-c51f-d88661d85923",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = get_train_generator()\n",
    "valid_generator = get_valid_generator()\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"custom_classifier_logs\")\n",
    "\n",
    "model.fit(train_generator, epochs=2,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate the final model we feed it with the test dataset and call the `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:custome_classifier_eval",
     "prev:custom_classifier",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "test_generator = get_test_generator()\n",
    "\n",
    "test_loss_custom, test_accuracy_custom = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"The accuracy in the test set is {test_accuracy_custom:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-kl1HXWo0mP",
    "tags": []
   },
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN (VGG16) to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "To reduce training time without sacrificing accuracy, we train a CNN using Transfer Learning. Transfer Learning is the fine-tuning of a network that was pre-trained on some big dataset with new classification layers. The idea behind is that we want to keep all the good features learned in the lower levels of the network (because there's a high probability the new images will also have those features) and just learn a new classifier on top of those. This tends to work well, especially with small datasets that don't allow for a full training of the network from scratch (it's also much faster than a full training).\n",
    "\n",
    "One way of doing Transfer Learning is by loading a pretrained model up to a point, usually chopping off the final dense part of the model and adding a fully connected layer with the output that we want (e.g. an 133-node classifier). Then, we freeze the first part of the model (i.e. the body) and train only the final layer we added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6fsA2R8nVBa",
    "tags": [
     "block:vgg16_classifier",
     "prev:data_processing",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "vgg_body = tf.keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szJl_qQ9sZuz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg_body.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdbFhBtIp-Jx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# We make sure that the vgg_body is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = vgg_body(inputs, training=False)\n",
    "# Convert features of shape `vgg_body.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier (categorical classification)\n",
    "outputs = tf.keras.layers.Dense(133, activation=\"softmax\")(x)\n",
    "\n",
    "vgg_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "9I2yPjo_qMTL",
    "outputId": "25b81b5f-e3d3-411c-d011-a20e18d38a11",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTMJ5joCqpTE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=LR),\n",
    "    loss=tf.losses.categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "8IoRWrQnq5c2",
    "outputId": "3f69f065-815e-4c9c-b665-ecc2a10337b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = get_train_generator()\n",
    "valid_generator = get_valid_generator()\n",
    "\n",
    "vgg_model.fit(train_generator, epochs=2,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate the model on the test set we call the same `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:vgg16_classifier_eval",
     "prev:vgg16_classifier"
    ]
   },
   "outputs": [],
   "source": [
    "test_generator = get_test_generator()\n",
    "\n",
    "test_loss_vgg, test_accuracy_vgg = vgg_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"The accuracy in the test set is {test_accuracy_vgg:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5: Create a CNN (ResNet-50) to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "In this section, we will use the same procedure but with a pretrained ResNet-50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:resnet50_classifier",
     "prev:data_processing",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "resnet_body = tf.keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet_body.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# We make sure that the vgg_body is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = resnet_body(inputs, training=False)\n",
    "# Convert features of shape `vgg_body.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# A Dense classifier (categorical classification)\n",
    "outputs = tf.keras.layers.Dense(133, activation=\"softmax\")(x)\n",
    "\n",
    "resnet_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=LR),\n",
    "    loss=tf.losses.categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = get_train_generator()\n",
    "valid_generator = get_valid_generator()\n",
    "\n",
    "resnet_model.fit(train_generator, epochs=EPOCHS,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:resnet50_classifier_eval",
     "prev:resnet50_classifier",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [],
   "source": [
    "test_generator = get_test_generator()\n",
    "\n",
    "test_loss_resnet, test_accuracy_resnet = resnet_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"The accuracy in the test set is {test_accuracy_resnet:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='step6'></a>\n",
    "## Step 6: Write your Own Dog Classifier\n",
    "\n",
    "To create our own classifier we need a class to predict if there is a dog in the image and if that's true, return the breed. For the first part we use the `dog_classifier` method and then predict the breed using the `predict_breed` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "idx_to_class = {value: key for key, value in train_generator.class_indices.items()}\n",
    "\n",
    "def predict_breed(images):\n",
    "    probs = resnet_model.predict(images)\n",
    "    pred = tf.argmax(probs, axis=1)\n",
    "    label = idx_to_class[pred.numpy()[0]]\n",
    "    return label.split(\".\")[-1]\n",
    "#end of def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "def predict_dog(image):\n",
    "    image = image[None,...]\n",
    "    if is_dog(image):\n",
    "        pred =  predict_breed(image)\n",
    "        print(f\"This photo looks like a(n) {pred}.\")\n",
    "        return\n",
    "\n",
    "    print(\"No dog detected\")\n",
    "#end of def\n",
    "\n",
    "image = train_generator.next()[0][0]\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "pred = predict_dog(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='step7'></a>\n",
    "## Step 7: Test Your Classifier\n",
    "\n",
    "In the last section, we take your new algorithm for a spin; if you have a dog, does it predict your dog's breed accurately? If you have a cat, does it mistakenly think that your cat is a dog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "for img_path in sorted(glob(\"check_images/*\")):\n",
    "    print(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    img = np.array(img)\n",
    "    predict_dog(img)\n",
    "#end of for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pipeline metrics\n",
    "\n",
    "This is the pipeline-metrics cell. Use it to define the pipeline metrics that KFP will produce for every pipeline run. Kale will associate each one of these metrics to the steps that produced them. Also, you will have to choose one these metrics as the Katib search objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-metrics"
    ]
   },
   "outputs": [],
   "source": [
    "print(test_accuracy_resnet)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dog-breed-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "experiment": {
    "id": "new",
    "name": "test-experiment"
   },
   "experiment_name": "test-experiment",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "dog-breed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
